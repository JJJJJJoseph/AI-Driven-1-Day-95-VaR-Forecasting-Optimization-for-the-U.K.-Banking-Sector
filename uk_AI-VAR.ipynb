{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# AI-Driven Optimization of 1-Day VaR (95%) for UK Banks â€” Notebook Header\n",
    "\n",
    "> # 1 Project Abstract. \n",
    "> This notebook implements a fully reproducible pipeline to forecast next-day 95% Value-at-Risk (VaR) for a portfolio of major UK bank equities (BARC.L, HSBA.L, LLOY.L, NWG.L, STAN.L). Classical benchmarks (GARCH-t, Historical Simulation, Filtered HS) are compared against a compact **LSTM Quantile Regression** and two **hybrids** (feature-fusion with GARCH volatility; convex ensemble). Exogenous drivers include realised volatility, macro state (BoE policy rate, UK 10-year yield) and **FinBERT** news sentiment (bank-specific and macro policy). Evaluation follows industry back-testing (Kupiec/Christoffersen) and proper quantile scoring (pinball loss), with **SHAP** and permutation importance for explainability. The design emphasises transparency, auditability and operational governance consistent with UK PRA SS1/23.\n",
    "\n",
    "---\n",
    "> # 2 Project Statement. \n",
    "## Data access & folders\n",
    "\n",
    "- **Market:** Yahoo Finance (`yfinance`) adjusted close for tickers above; daily portfolio return equals equal-weighted bank basket.  \n",
    "- **Macro:** FRED series `BOERUKM` (Bank Rate) and `IRLTLT01GBM156N` (10Y yield), business-day aligned via forward-fill; FTSE-100 level for context.  \n",
    "- **Sentiment:** Kaggle news archives (e.g., *News_Category_Dataset_v3.json*, NYT articles) filtered to UK-bank and macro keywords; **FinBERT** polarity averaged into daily indices.  \n",
    "- **Drive layout (mounted at `/content/drive`)**  \n",
    "```\n",
    "\n",
    "/MyDrive/ai-var/\n",
    "â”œâ”€ data/\n",
    "â”‚   â”œâ”€ prices/        # Yahoo CSV cache\n",
    "â”‚   â”œâ”€ macro/         # FRED CSV\n",
    "â”‚   â””â”€ sentiment/     # Kaggle raw + scored daily series\n",
    "â”œâ”€ features/          # engineered feature tables\n",
    "â”œâ”€ models/            # saved .pt/.pkl and VaR forecasts\n",
    "â”œâ”€ eda/               # figures and summary tables\n",
    "â””â”€ reports/           # comparison tables for paper\n",
    "\n",
    "````\n",
    "\n",
    "---\n",
    "\n",
    "## Dependencies (tested versions)\n",
    "\n",
    "- Python â‰¥ 3.11  \n",
    "- `pandas` â‰¥ 2.2, `numpy` â‰¥ 1.26, `scipy` â‰¥ 1.11  \n",
    "- `yfinance` â‰¥ 0.2.40, `fredapi` â‰¥ 0.5.2  \n",
    "- `arch` â‰¥ 6.3, `statsmodels` â‰¥ 0.14  \n",
    "- `torch` â‰¥ 2.2, `scikit-learn` â‰¥ 1.4  \n",
    "- `transformers` â‰¥ 4.41, `shap` â‰¥ 0.45  \n",
    "- `matplotlib` â‰¥ 3.8, `seaborn` â‰¥ 0.13 (plots)\n",
    "\n",
    "> **Print runtime versions (optional):**\n",
    "> ```python\n",
    "> import sys, torch, pandas as pd, numpy as np, sklearn, shap, transformers, arch, statsmodels, yfinance\n",
    "> print(\"Python\", sys.version); print(\"torch\", torch.__version__); print(\"pandas\", pd.__version__)\n",
    "> print(\"numpy\", np.__version__, \"sklearn\", sklearn.__version__, \"shap\", shap.__version__, \"transformers\", transformers.__version__)\n",
    "> print(\"arch\", arch.__version__, \"statsmodels\", statsmodels.__version__, \"yfinance\", yfinance.__version__)\n",
    "> ```\n",
    "\n",
    "---\n",
    "\n",
    "## How to run (end-to-end)\n",
    "\n",
    "1. **Environment** â€” install requirements; mount Google Drive.  \n",
    "2. **Data download** â€” fetch bank prices (Yahoo), macro (FRED), and load Kaggle news files into `/data/sentiment/`.  \n",
    "3. **Sentiment scoring** â€” run FinBERT to create daily `sent_bank`/`sent_macro` series.  \n",
    "4. **Feature engineering** â€” compute returns, `abs_ret`, `rv_30d`, macro z-scores, rolling sentiment (e.g., 7-day MA); save to `/features/uk_features.parquet`.  \n",
    "5. **EDA** â€” produce distribution, QQ-plot, correlations, rolling sentimentâ€“volatility diagnostics; figures to `/eda/`.  \n",
    "6. **Baselines** â€” fit GARCH-t; roll **HS/FHS** VaR; store daily VaR to `/models/VAR/`.  \n",
    "7. **LSTM-QR** â€” scale features (train-only stats), build 60-day sequences, train with early-stopping; save `best_model.pt` and predictions.  \n",
    "8. **Hybrids** â€” feature-fusion with GARCH Ïƒ (Hybrid-Feat); convex ensemble (Hybrid-Ens).  \n",
    "9. **Back-testing** â€” compute breaches, Kupiec/Christoffersen p-values, pinball/mean-excess loss; DM tests for loss differentials.  \n",
    "10. **XAI** â€” SHAP bars/beeswarm, permutation importance; export to `/reports/`.  \n",
    "11. **Persist** â€” dump artefacts (`.pt`, scalers, config JSON, comparison CSV) under `/models/` and `/reports/`.\n",
    "\n",
    "> **Reproducibility:** set RNG seeds (NumPy/Torch), fix train/val/test temporal splits, log configuration (window lengths, hyper-parameters, data timestamps) in a `config.json`.\n",
    "\n",
    "---\n",
    "\n",
    "## Model governance (SS1/23 alignment)\n",
    "\n",
    "The notebook retains challenger **benchmarks** alongside AI models, records full **data lineage** and configuration versions, produces **explainability artefacts** (SHAP/perm-importance), and saves **coverage & loss** dashboards for monitoring and change controlâ€”all consistent with PRA **SS1/23** principles on documentation, performance monitoring and model change governance.\n",
    "\n",
    "---\n",
    "\n",
    "## Ethics & data use\n",
    "\n",
    "Only public/licensed datasets are used; no personal data are processed. News ingestion respects provider licences; code avoids scraping gated content. Sentiment biases are mitigated via domain filters and robustness checks. Forecasts are for research; not investment advice.\n",
    "\n",
    "---\n",
    "````\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajBDAFGoqFhx"
   },
   "source": [
    "# 3 PIP Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 113815,
     "status": "ok",
     "timestamp": 1751152380335,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "XNo5b9brp44n",
    "outputId": "4fdbd948-46ff-4c04-b349-ceb5a82c0703"
   },
   "outputs": [],
   "source": [
    "# Install core libraries for data, stats, ML, and NLP\n",
    "!pip install --quiet yfinance pandas_datareader fredapi arch \\\n",
    "    numpy scipy pandas matplotlib seaborn \\\n",
    "    torch torchvision torcheval \\\n",
    "    transformers sentencepiece \\\n",
    "    shap tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DKE1R-NRvKjZ"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet kaggle transformers torch tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7201,
     "status": "ok",
     "timestamp": 1751152431356,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "lz2DJ8FeqJpF",
    "outputId": "ecd8a4d9-0474-4c90-a62b-66c851939ea3"
   },
   "outputs": [],
   "source": [
    "# Core imports and version checks\n",
    "import sys, platform, datetime, torch, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Python version:\", sys.version.split()[0])\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"GPU available:\", torch.cuda.is_available())\n",
    "print(\"Current time:\", datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2LCFhWbql7L"
   },
   "outputs": [],
   "source": [
    "# Data acquisition\n",
    "import yfinance as yf\n",
    "from pandas_datareader import data as pdr\n",
    "from fredapi import Fred\n",
    "\n",
    "# Econometrics & stats\n",
    "from arch import arch_model\n",
    "from scipy import stats\n",
    "\n",
    "# NLP\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEpHm4kcq6m5"
   },
   "source": [
    "# 4 Bank Data Downloading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfeANZ-4sMZe"
   },
   "source": [
    "1. UK Banks Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdZc0JbJqzJM"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "import datetime, yfinance as yf, pandas as pd, numpy as np\n",
    "\n",
    "# UK bank tickers on LSE (suffix .L)\n",
    "tickers = [\"HSBA.L\", \"BARC.L\", \"LLOY.L\", \"NWG.L\", \"STAN.L\"]\n",
    "start_date = \"2010-01-01\"\n",
    "end_date   = \"2025-06-30\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 653,
     "status": "ok",
     "timestamp": 1751066308949,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "eQiz47J5rKm7",
    "outputId": "d625546f-ca68-4498-a953-cef6a33026f5"
   },
   "outputs": [],
   "source": [
    "# auto_adjust=False â‡’ keep original OHLC + Adj Close\n",
    "data = yf.download(\n",
    "    tickers,\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    auto_adjust=False,     # <-- key line\n",
    "    progress=False         # silence the progress bar\n",
    ")\n",
    "\n",
    "# Keep only the 'Adj Close' price for each ticker\n",
    "# data has a 2-level column index: (ticker, field)\n",
    "prices = data['Adj Close']          # level-1 slice\n",
    "prices.columns = prices.columns.get_level_values(0)  # flatten ticker names\n",
    "\n",
    "# Align to business days & forward-fill\n",
    "prices = prices.asfreq(\"B\").ffill()\n",
    "\n",
    "# Compute daily log-returns\n",
    "returns = np.log(prices / prices.shift(1)).dropna()\n",
    "\n",
    "print(\"prices shape:\", prices.shape)\n",
    "print(\"returns shape:\", returns.shape)\n",
    "prices.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDb31JMQrOPd"
   },
   "outputs": [],
   "source": [
    "# Save to Drive for persistence\n",
    "prices.to_csv(\"/content/drive/MyDrive/ai-var/data/uk_banks_prices.csv\")\n",
    "returns.to_csv(\"/content/drive/MyDrive/ai-var/data/uk_banks_returns.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wnMk5DGsUY4"
   },
   "source": [
    "2. Macro Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oKTPPYotr_O5"
   },
   "outputs": [],
   "source": [
    "# Replace 'YOUR_FRED_KEY' with your real key\n",
    "import os\n",
    "os.environ[\"FRED_API_KEY\"] = \"9c6d07fa024811d37ff986edd232f7c7\"\n",
    "from fredapi import Fred\n",
    "fred = Fred()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 957,
     "status": "ok",
     "timestamp": 1751067011856,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "g1jyLyMTspzI",
    "outputId": "02fab940-ea35-4d2a-d4ff-9aba357a80b8"
   },
   "outputs": [],
   "source": [
    "# ----------------- 0.  å‡†å¤‡ -----------------\n",
    "import pandas as pd, numpy as np, yfinance as yf, os\n",
    "from fredapi import Fred\n",
    "\n",
    "start_date, end_date = \"2010-01-01\", \"2025-06-30\"\n",
    "fred = Fred(api_key=os.getenv(\"9c6d07fa024811d37ff986edd232f7c7\"))\n",
    "\n",
    "def fetch_fred(id_list):\n",
    "    for sid in id_list:\n",
    "        try:\n",
    "            s = fred.get_series(sid, observation_start=start_date, observation_end=end_date)\n",
    "            if s is not None and s.dropna().size:\n",
    "                print(f\"  FRED {sid} âœ“  ({s.size} obs)\")\n",
    "                return s\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def fetch_yahoo(ticker, price_field=\"Close\"):\n",
    "    try:\n",
    "        df = yf.download(ticker, start=start_date, end=end_date,\n",
    "                         auto_adjust=False, progress=False)\n",
    "        if price_field not in df.columns:\n",
    "            print(f\"  Field '{price_field}' missing for {ticker}\")\n",
    "            return None\n",
    "        s = df[price_field]\n",
    "        if s.dropna().size:\n",
    "            print(f\"  Yahoo {ticker} âœ“  ({s.size} obs)\")\n",
    "            return s\n",
    "    except Exception as e:\n",
    "        print(f\"  Yahoo {ticker} failed: {e}\")\n",
    "    return None\n",
    "\n",
    "# ----------------- 1.  æ”¶é›†å®è§‚åºåˆ— -----------------\n",
    "macro_df = pd.DataFrame()\n",
    "\n",
    "# (1) BoE Base Rate\n",
    "macro_df[\"boe_rate\"] = fetch_fred([\"BOERUKM\"])\n",
    "\n",
    "# (2) 10Yãƒ»2Y è‹±å€ºæ”¶ç›ŠçŽ‡ (BoE Par Yield ç³»åˆ—)\n",
    "macro_df[\"yield_10y\"] = fetch_fred([\"IUDMNPY10\", \"IRLTLT01GBM156N\"])\n",
    "macro_df[\"yield_2y\"]  = fetch_fred([\"IUDMNPY2\" , \"IRTLT02GBM156N\"])\n",
    "\n",
    "# (3) ä¿¡ç”¨åˆ©å·®ï¼ˆç¼ºå°‘å¯é å…¬å¼€æº â†’ æš‚æ—¶è·³è¿‡ï¼‰\n",
    "\n",
    "# ----------------- 2.  è®¡ç®—åˆ©å·® -----------------\n",
    "if {\"yield_10y\", \"yield_2y\"}.issubset(macro_df.columns):\n",
    "    macro_df[\"yield_spread\"] = macro_df[\"yield_10y\"] - macro_df[\"yield_2y\"]\n",
    "    print(\"yield_spread created.\")\n",
    "else:\n",
    "    print(\"yield_spread skipped.\")\n",
    "\n",
    "# ----------------- 3.  è‚¡æŒ‡ä¸Žæ³¢åŠ¨çŽ‡ -----------------\n",
    "ftse_close = fetch_yahoo(\"^FTSE\", \"Close\")     # FTSE 100 ä»·æ ¼\n",
    "macro_df[\"ftse_level\"] = ftse_close            # å¯èƒ½ä¸ºç©ºï¼Œç¨åŽå† dropna\n",
    "\n",
    "# 30-day realised volatility proxy for FTSE 100\n",
    "if ftse_close is not None:\n",
    "    log_ret = np.log(ftse_close / ftse_close.shift(1))\n",
    "    macro_df[\"vftse_proxy\"] = log_ret.rolling(30).std() * np.sqrt(252)\n",
    "    print(\"vftse_proxy (30-day realised vol) created.\")\n",
    "\n",
    "# ----------------- 4.  å¯¹é½é¢‘çŽ‡ & æ¸…ç† -----------------\n",
    "macro_df = (macro_df\n",
    "            .asfreq(\"B\")      # business day\n",
    "            .ffill()          # å‰å‘å¡«å……\n",
    "            .dropna(axis=1, how=\"all\"))  # ç§»é™¤å…¨ç©ºåˆ—\n",
    "\n",
    "print(\"Current columns:\", macro_df.columns.tolist())\n",
    "print(\"Shape:\", macro_df.shape)\n",
    "\n",
    "# æŒä¹…åŒ–\n",
    "macro_df.to_csv(\"/content/drive/MyDrive/ai-var/data/uk_macro_daily.csv\")\n",
    "\n",
    "# 5. Align to full business-day calendar, then ffill\n",
    "full_biz_index = pd.date_range(start=start_date, end=end_date, freq=\"B\")\n",
    "macro_df = macro_df.reindex(full_biz_index).ffill()\n",
    "\n",
    "# Optional: silence downcast warning\n",
    "macro_df = macro_df.infer_objects(copy=False)\n",
    "\n",
    "print(\"After reindex, shape:\", macro_df.shape)\n",
    "print(macro_df.head(), \"\\n\", macro_df.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwMOWTMWvgKf"
   },
   "source": [
    "# 5 Sentiment Data and Finbert Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 959,
     "status": "ok",
     "timestamp": 1751068065399,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "IF-7RPOPvqzG",
    "outputId": "21f70e37-4d6d-4fd8-bd54-d30fc543b18b"
   },
   "outputs": [],
   "source": [
    "# Move kaggle.json to ~/.kaggle and set permission\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp /content/drive/MyDrive/ai-var/kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# ç¡®è®¤ Kaggle CLI èƒ½åˆ—å†…å®¹\n",
    "!kaggle datasets list -s reuters -p 10 | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 719,
     "status": "ok",
     "timestamp": 1751068649353,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "OHpAuj7q0xoa",
    "outputId": "b26b4030-1d56-4c65-bd7b-9a4272bb936c"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets list -s titanic -p 5 | head   # åªåˆ—å‰ 5 è¡Œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 169571,
     "status": "ok",
     "timestamp": 1751069582423,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "9wIV34TqxwAe",
    "outputId": "d73850b4-03c8-4109-e463-f83cdb9de3c4"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download -d rmisra/news-category-dataset -p /content/drive/MyDrive/ai-var/data/sentiment/ --unzip\n",
    "# BuzzFeed\n",
    "!kaggle datasets download -d konradb/buzzfeed-news-2018-2023 -p /content/drive/MyDrive/ai-var/data/sentiment/ --unzip\n",
    "# NYT 2020\n",
    "!kaggle datasets download -d benjaminawd/new-york-times-articles-comments-2020 -p /content/drive/MyDrive/ai-var/data/sentiment/ --unzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47400,
     "status": "ok",
     "timestamp": 1751072981136,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "JZY_VJl43V27",
    "outputId": "797c0165-90ca-458b-8928-554873075878"
   },
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 1. imports & FinBERT\n",
    "# ================================================================\n",
    "import glob, os, pandas as pd, numpy as np, torch, tqdm, datetime as dt\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "DEVICE      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE  = 48\n",
    "MAX_LEN     = 64\n",
    "\n",
    "tok  = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "mdl  = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\").to(DEVICE).eval()\n",
    "\n",
    "def finbert_scores(texts, bs=BATCH_SIZE):\n",
    "    out=[]\n",
    "    for i in range(0, len(texts), bs):\n",
    "        batch = texts[i:i+bs]\n",
    "        inp = tok(batch, truncation=True, padding=True,\n",
    "                  max_length=MAX_LEN, return_tensors=\"pt\").to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            p = softmax(mdl(**inp).logits, dim=1).cpu().numpy()\n",
    "        out.extend((p[:,0]-p[:,1]).tolist())   # P(pos)-P(neg)\n",
    "    return np.array(out)\n",
    "\n",
    "# ================================================================\n",
    "# 2. keyword list (å·²æ‰©å……)\n",
    "# ================================================================\n",
    "bank_kw  = [\"hsbc\",\"barclays\",\"lloyds\",\"natwest\",\"standard chartered\",\n",
    "            \"hsba\",\"barc\",\"lloy\",\"nwg\",\"stan\",\n",
    "            \"uk bank\",\"lender\",\"loan book\",\"credit loss\",\"profit warning\",\n",
    "            \"trading desk\",\"capital ratio\"]\n",
    "macro_kw = [\"bank of england\",\"boe\",\"interest rate\",\"inflation\",\"gdp\",\n",
    "            \"brexit\",\"uk economy\",\"unemployment\",\"recession\",\"bond yield\",\n",
    "            \"gilt\",\"sterling\",\"budget\",\"fiscal policy\",\"tax cut\"]\n",
    "\n",
    "def has_kw(text, kws):\n",
    "    t = str(text).lower()\n",
    "    return any(k in t for k in kws)\n",
    "\n",
    "# ================================================================\n",
    "# 3. dataset config table  (è·¯å¾„å¯æ”¹)\n",
    "# ================================================================\n",
    "DATA_DIR = \"/content/drive/MyDrive/ai-var/data/sentiment/\"       # <-- ä¿®æ”¹ä¸ºä½ å­˜æ”¾è§£åŽ‹æ–‡ä»¶çš„ç›®å½•\n",
    "\n",
    "datasets_cfg = [\n",
    "    # pattern (glob),                         date_cands,                     text_cols\n",
    "    (\"**/News_Category_Dataset_v3.json\",      ['date'],                       ['headline','short_description']),\n",
    "    (\"**/nyt-articles-2020.csv\",              ['pub_date','date'],            ['headline','abstract']),\n",
    "    (\"**/bfn-trending-strip-deduped.tsv\",     ['timestamp','date','publish_date'], ['title','description']),\n",
    "]\n",
    "\n",
    "def load_any(path, date_cols, text_cols):\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    sep = '\\t' if ext == '.tsv' else ','\n",
    "    print(\"â†’ loading\", os.path.basename(path))\n",
    "    df = (pd.read_json(path, lines=True) if ext=='.json'\n",
    "          else pd.read_csv(path, sep=sep, low_memory=False))\n",
    "\n",
    "    # pick first available date column\n",
    "    date_col = next((c for c in date_cols if c in df.columns), None)\n",
    "    if date_col is None:\n",
    "        raise ValueError(f\"{path}: no date col among {date_cols}\")\n",
    "    df['date'] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "    df = df.dropna(subset=['date'])          # remove NaT rows\n",
    "\n",
    "    for col in text_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = ''\n",
    "    df['text'] = df[text_cols].fillna('').agg(' '.join, axis=1)\n",
    "    return df[['date','text']]\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3a. load all configured datasets\n",
    "# ------------------------------------------------\n",
    "df_list = []\n",
    "for pattern, dcols, tcols in datasets_cfg:\n",
    "    for fp in glob.glob(os.path.join(DATA_DIR, pattern), recursive=True):\n",
    "        try:\n",
    "            df_list.append(load_any(fp, dcols, tcols))\n",
    "        except Exception as e:\n",
    "            print(\"  skip:\", e)\n",
    "\n",
    "news_df = pd.concat(df_list, ignore_index=True)\n",
    "print(\"Total merged rows:\", news_df.shape[0])\n",
    "\n",
    "# ================================================================\n",
    "# 4. keyword filter\n",
    "# ================================================================\n",
    "news_df['bank_flag']  = news_df['text'].apply(lambda x: has_kw(x, bank_kw))\n",
    "news_df['macro_flag'] = news_df['text'].apply(lambda x: has_kw(x, macro_kw))\n",
    "\n",
    "bank_df  = news_df[news_df.bank_flag]\n",
    "macro_df = news_df[news_df.macro_flag]\n",
    "print(\"Bank rows:\", bank_df.shape[0], \"| Macro rows:\", macro_df.shape[0])\n",
    "\n",
    "# ================================================================\n",
    "# 5. robust daily sentiment function (fix .dt bug)\n",
    "# ================================================================\n",
    "def daily_sentiment(sub_df, sent_col, vol_col):\n",
    "    if sub_df.empty:\n",
    "        return pd.DataFrame(columns=[sent_col, vol_col])\n",
    "\n",
    "    sub_df = sub_df.copy()\n",
    "    sub_df['date'] = pd.to_datetime(sub_df['date'], errors='coerce')\n",
    "    sub_df = sub_df.dropna(subset=['date'])\n",
    "\n",
    "    print(f\"Scoring {sent_col} â€” {len(sub_df)} articles\")\n",
    "    sub_df.loc[:, 'score'] = finbert_scores(sub_df['text'].tolist())\n",
    "\n",
    "    daily = (sub_df\n",
    "             .groupby(sub_df['date'].dt.date)['score']\n",
    "             .agg(['mean','count'])\n",
    "             .rename(columns={'mean': sent_col, 'count': vol_col}))\n",
    "    return daily\n",
    "\n",
    "bank_daily  = daily_sentiment(bank_df,  'sent_bank',  'vol_bank')\n",
    "macro_daily = daily_sentiment(macro_df, 'sent_macro', 'vol_macro')\n",
    "\n",
    "sentiment = pd.concat([bank_daily, macro_daily], axis=1).sort_index()\n",
    "\n",
    "# align to business-day index\n",
    "biz_idx  = pd.date_range(sentiment.index.min(), sentiment.index.max(), freq='B')\n",
    "sentiment = (sentiment\n",
    "             .reindex(biz_idx)\n",
    "             .fillna(0.0)\n",
    "             .infer_objects(copy=False))\n",
    "\n",
    "print(\"Final sentiment shape:\", sentiment.shape)\n",
    "\n",
    "# ================================================================\n",
    "# 6. save to Google Drive\n",
    "# ================================================================\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "OUT_CSV = \"/content/drive/MyDrive/ai-var/data/uk_sentiment_daily.csv\"\n",
    "sentiment.to_csv(OUT_CSV)\n",
    "print(\"âœ… Sentiment CSV saved to:\", OUT_CSV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BN9tSDmkGBx5"
   },
   "source": [
    "# 6 Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1751073752149,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "uRcp34AjH3Ba",
    "outputId": "11504d11-3c5d-444b-f948-55f2e4f9c208"
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "\n",
    "RET_PATH = \"/content/drive/MyDrive/ai-var/data/uk_banks_returns.csv\"\n",
    "returns_raw = pd.read_csv(RET_PATH, index_col=0, parse_dates=True)\n",
    "\n",
    "# æŠŠæ‰€æœ‰åˆ—è½¬æ¢æˆæ•°å€¼ (æœ‰ç©ºå­—ç¬¦ä¸²ä¼šå˜ NaN)\n",
    "returns_raw = returns_raw.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# ---------- æ–¹æ¡ˆ A: ç­‰æƒç»„åˆ ----------\n",
    "returns_raw['return'] = returns_raw.mean(axis=1)      # ç®€å•å¹³å‡\n",
    "\n",
    "returns_raw.to_csv(\"/content/drive/MyDrive/ai-var/data/uk_bank_returns.csv\")\n",
    "print(\"âœ… created 'return' column â€” shape now\", returns_raw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3100,
     "status": "ok",
     "timestamp": 1751152488907,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "0oTlEsDU8aTG",
    "outputId": "317ef1fd-b184-4fbc-81ac-eebed85885c1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "RET_PATH  = \"/content/drive/MyDrive/ai-var/data/uk_bank_returns.csv\"\n",
    "MACRO_PATH= \"/content/drive/MyDrive/ai-var/data/uk_macro_daily.csv\"\n",
    "SENT_PATH = \"/content/drive/MyDrive/ai-var/data/uk_sentiment_daily.csv\"\n",
    "\n",
    "returns = pd.read_csv(RET_PATH,  index_col=0, parse_dates=True)\n",
    "macro   = pd.read_csv(MACRO_PATH, index_col=0, parse_dates=True)\n",
    "sent    = pd.read_csv(SENT_PATH,  index_col=0, parse_dates=True)\n",
    "\n",
    "# ä»¥ returns ä¸ºä¸»è½´å·¦è¿žæŽ¥\n",
    "df = (returns\n",
    "      .join([macro, sent], how='left')\n",
    "      .sort_index())\n",
    "\n",
    "# å…ˆ forward-fill å®è§‚ï¼Œå†æŠŠæƒ…ç»ª NaN â†’ 0\n",
    "macro_cols = macro.columns.tolist()\n",
    "sent_cols  = ['sent_bank','vol_bank','sent_macro','vol_macro']\n",
    "df[macro_cols] = df[macro_cols].fillna(method='ffill')\n",
    "df[sent_cols]  = df[sent_cols].fillna(0.0)\n",
    "\n",
    "print(\"Merged shape:\", df.shape)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjb_oD2JGTsx"
   },
   "outputs": [],
   "source": [
    "# ç»å¯¹æ”¶ç›Šã€å¹³æ–¹æ”¶ç›Š\n",
    "df['abs_ret']   = df['return'].abs()\n",
    "df['ret_sq']    = df['return']**2\n",
    "\n",
    "# å®žçŽ°æ³¢åŠ¨çŽ‡ (30d)\n",
    "df['rv_30d'] = df['return'].rolling(30).std()\n",
    "\n",
    "# æ»šåŠ¨å‡å€¼æ”¶ç›Š (5d)\n",
    "df['ret_mean_5d'] = df['return'].rolling(5).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xPAqrI4EG0nl"
   },
   "outputs": [],
   "source": [
    "# 7 å¤©æ»šåŠ¨å‡å€¼ & z-score\n",
    "for col in ['sent_bank','sent_macro']:\n",
    "    df[f'{col}_7d'] = df[col].rolling(7, min_periods=1).mean()\n",
    "\n",
    "# æ–°é—»é‡ 30 å¤©ç´¯è®¡\n",
    "df['vol_bank_30d']  = df['vol_bank'].rolling(30).sum()\n",
    "df['vol_macro_30d'] = df['vol_macro'].rolling(30).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yi2AJFbsHcP_"
   },
   "outputs": [],
   "source": [
    "# ä¸€é˜¶å·®åˆ† / å¯¹æ•°å·®åˆ†\n",
    "df['boe_rate_diff']  = df['boe_rate'].diff()\n",
    "df['yield_10y_diff'] = df['yield_10y'].diff()\n",
    "\n",
    "# å¯¹å®è§‚åš z-scoreï¼ˆåŸºäºŽå…¨éƒ¨æ ·æœ¬ï¼‰\n",
    "for col in ['boe_rate','yield_10y','boe_rate_diff','yield_10y_diff']:\n",
    "    df[f'{col}_z'] = (df[col] - df[col].mean()) / df[col].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1751152497054,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "DLrprh8dHfS-",
    "outputId": "08ca0038-6c63-4816-8f2d-e522899f3621"
   },
   "outputs": [],
   "source": [
    "# å‰©ä½™ NaNï¼ˆå›  rolling å¯¼è‡´å‰å‡ è¡Œç¼ºå€¼ï¼‰â†’ ä¸¢å¼ƒ\n",
    "df = df.dropna()\n",
    "\n",
    "# Winsorize: æŠŠ return æžç«¯ 0.5% ä¿®æ­£åˆ°é˜ˆå€¼\n",
    "lo, hi = df['return'].quantile([0.005, 0.995])\n",
    "df['return'] = df['return'].clip(lo, hi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwzCLsClKqF5"
   },
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 6-6  ä¿å­˜å¤„ç†å®Œçš„ç‰¹å¾è¡¨ & æ ‡å‡†åŒ–å™¨\n",
    "# ======================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib, os\n",
    "\n",
    "# ------------ é…ç½® ------------\n",
    "FEATURES = ['return','abs_ret','rv_30d','ret_mean_5d',\n",
    "            'sent_bank_7d','sent_macro_7d',\n",
    "            'vol_bank_30d','vol_macro_30d',\n",
    "            'boe_rate_z','yield_10y_z','boe_rate_diff_z','yield_10y_diff_z']\n",
    "TARGET   = 'return'\n",
    "SAVE_DIR = \"/content/drive/MyDrive/ai-var/processed\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ------------ æ‹†åˆ† & æ ‡å‡†åŒ– ------------\n",
    "split_date = '2022-01-01'\n",
    "train_df   = df.loc[:split_date].copy()\n",
    "test_df    = df.loc[split_date:].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_df[FEATURES] = scaler.fit_transform(train_df[FEATURES])\n",
    "test_df[FEATURES]  = scaler.transform(test_df[FEATURES])\n",
    "\n",
    "# ------------ åˆå¹¶å›žå®Œæ•´é›†ï¼ˆæ–¹ä¾¿ç»Ÿä¸€å­˜å‚¨ï¼‰ ------------\n",
    "df_scaled = pd.concat([train_df, test_df]).sort_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1494,
     "status": "ok",
     "timestamp": 1751155923938,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "YT5cm1CoNMIy",
    "outputId": "a280d32d-e5be-472d-a812-70e385842f49"
   },
   "outputs": [],
   "source": [
    "# ------------ ä¿å­˜æ•°æ® ------------\n",
    "parquet_path = f\"/content/drive/MyDrive/ai-var/models/uk_features_scaled.parquet\"\n",
    "csv_path     = f\"/content/drive/MyDrive/ai-var/models/uk_features_scaled.csv.gz\"\n",
    "scaler_path  = f\"/content/drive/MyDrive/ai-var/models/feature_scaler.bin\"\n",
    "\n",
    "df_scaled.to_parquet(parquet_path, compression='snappy')\n",
    "df_scaled.to_csv(csv_path, compression='gzip')\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "print(\"âœ… Saved:\")\n",
    "print(\"  Â· Parquet :\", parquet_path)\n",
    "print(\"  Â· CSV (gz):\", csv_path)\n",
    "print(\"  Â· Scaler  :\", scaler_path)\n",
    "print(\"Shape:\", df_scaled.shape, \" | Columns:\", df_scaled.columns.tolist()[:10], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCPPBr_jMTVO"
   },
   "source": [
    "# 7 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1751075153796,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "Erg47gVmLbHT",
    "outputId": "38231943-5670-42d2-ad3f-bd9876a7c14d"
   },
   "outputs": [],
   "source": [
    "#7-Aï¸âƒ£ æ•°æ®æ¦‚è§ˆ & ç¼ºå¤±æƒ…å†µ\n",
    "print(df_scaled.info())\n",
    "print(df_scaled.describe(percentiles=[.01,.05,.5,.95,.99]))\n",
    "\n",
    "# missing value heatmap\n",
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "sns.heatmap(df_scaled.isna(), cbar=False)\n",
    "plt.title(\"Missing value map\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 924
    },
    "executionInfo": {
     "elapsed": 1056,
     "status": "ok",
     "timestamp": 1751074948255,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "2zM0Y_ILMri9",
    "outputId": "6842340b-302f-4533-e8e0-03ddc37a314b"
   },
   "outputs": [],
   "source": [
    "7-Bï¸âƒ£ æ”¶ç›Šåˆ†å¸ƒç‰¹å¾\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "# Histogram + kernel density\n",
    "df_scaled['return'].plot(kind='hist', bins=80, density=True, alpha=0.6)\n",
    "df_scaled['return'].plot(kind='kde', linewidth=2)\n",
    "plt.title(\"Distribution of daily log return\"); plt.show()\n",
    "\n",
    "# QQ-plot vs Normal\n",
    "qqplot(df_scaled['return'], line='s')\n",
    "plt.title(\"QQ-plot (return vs Normal)\"); plt.show()\n",
    "\n",
    "# Jarque-Bera test for normality\n",
    "jb_stat, jb_p = st.jarque_bera(df_scaled['return'])\n",
    "print(f\"Jarque-Bera stat={jb_stat:.2f},  p-value={jb_p:.3g}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4500,
     "status": "ok",
     "timestamp": 1751075069297,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "3-UZ0RqUMz8j",
    "outputId": "a898e3a5-3dc4-49b4-e032-051a0c57d4dd"
   },
   "outputs": [],
   "source": [
    "7-Cï¸âƒ£ æ—¶åºå¯è§†åŒ–ï¼šæ”¶ç›Šã€æ³¢åŠ¨ã€æƒ…ç»ªã€å®è§‚\n",
    "fig, ax = plt.subplots(4,1, figsize=(12,10), sharex=True)\n",
    "df_scaled['return'].plot(ax=ax[0]); ax[0].set_title(\"Daily return\")\n",
    "df_scaled['rv_30d'].plot(ax=ax[1]); ax[1].set_title(\"30-day realised vol\")\n",
    "df_scaled['sent_bank_7d'].plot(ax=ax[2]); ax[2].set_title(\"Bank sentiment 7-day MA\")\n",
    "df_scaled['boe_rate_z'].plot(ax=ax[3]); ax[3].set_title(\"BOE rate (z-score)\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 875
    },
    "executionInfo": {
     "elapsed": 1500,
     "status": "ok",
     "timestamp": 1751075091414,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "bBq4r2UjNQp7",
    "outputId": "25298e8f-7cf5-4d3d-d0f5-19fdea7c3def"
   },
   "outputs": [],
   "source": [
    "7-Dï¸âƒ£ ç›¸å…³æ€§çŸ©é˜µ & æ»šåŠ¨ç›¸å…³\n",
    "import seaborn as sns\n",
    "\n",
    "corr = df_scaled[['return','abs_ret','rv_30d',\n",
    "                  'sent_bank_7d','sent_macro_7d',\n",
    "                  'boe_rate_z','yield_10y_z']].corr()\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Pearson correlation matrix\"); plt.show()\n",
    "\n",
    "# 180-day rolling correlation between sentiment & volatility\n",
    "roll = df_scaled[['sent_bank_7d','rv_30d']].rolling(180).corr().dropna()\n",
    "roll.loc[pd.IndexSlice[:,'sent_bank_7d'],'rv_30d'].droplevel(1).plot(figsize=(9,3))\n",
    "plt.axhline(0, color='k', ls='--'); plt.title(\"Rolling corr: sentiment vs vol\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "executionInfo": {
     "elapsed": 1197,
     "status": "ok",
     "timestamp": 1751075104279,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "QZE9ldMlNWyD",
    "outputId": "f6c414d1-5dbd-4c69-ed44-e34e0c67396e"
   },
   "outputs": [],
   "source": [
    "7-Eï¸âƒ£ æƒ…ç»ªæ»žåŽä¸Žæœªæ¥æ³¢åŠ¨\n",
    "# 1 æ—¥åŽç»å¯¹æ”¶ç›Šä½œä¸ºç›®æ ‡\n",
    "df_tmp = pd.DataFrame({\n",
    "    'sent_bank_7d' : df_scaled['sent_bank_7d'],\n",
    "    'abs_ret_t+1'  : df_scaled['abs_ret'].shift(-1)\n",
    "}).dropna()\n",
    "\n",
    "sns.regplot(x='sent_bank_7d', y='abs_ret_t+1', data=df_tmp,\n",
    "            scatter_kws={'s':10, 'alpha':0.3})\n",
    "plt.title(\"Bank sentiment vs next-day abs return\"); plt.show()\n",
    "\n",
    "rho = df_tmp.corr().iloc[0,1]\n",
    "print(\"Pearson corr (sentiment vs next-day volatility):\", rho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "executionInfo": {
     "elapsed": 1645,
     "status": "ok",
     "timestamp": 1751075131809,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "CdxLLZHpNaAA",
    "outputId": "c0dda642-4e28-4c3c-cc0b-846022957ddc"
   },
   "outputs": [],
   "source": [
    "7-Fï¸âƒ£ å¹³ç¨³æ€§å’Œè‡ªç›¸å…³\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf, q_stat\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "adf_stat, adf_p, *_ = adfuller(df_scaled['return'])\n",
    "print(f\"ADF stat={adf_stat:.2f}  p-value={adf_p:.3g}\")\n",
    "\n",
    "fig, ax = plt.subplots(2,1, figsize=(10,6))\n",
    "plot_acf(df_scaled['return'], lags=40, ax=ax[0])\n",
    "plot_pacf(df_scaled['return'], lags=40, ax=ax[1]); plt.show()\n",
    "\n",
    "# Ljung-Box for up to 10 lags\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "lb = acorr_ljungbox(df_scaled['return'], lags=[10], return_df=True)\n",
    "print(lb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8066,
     "status": "ok",
     "timestamp": 1751075381897,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "OEZAkPmbNgmq",
    "outputId": "80cee484-31ae-4e7e-d39e-792a39ac5fd4"
   },
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# Set directory to save all EDA outputs\n",
    "# ==============================================================\n",
    "import os, matplotlib.pyplot as plt, seaborn as sns, numpy as np, pandas as pd\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "EDA_DIR = \"/content/drive/MyDrive/ai-var/eda\"\n",
    "os.makedirs(EDA_DIR, exist_ok=True)\n",
    "\n",
    "# ------------- Helper to save and clear --------------\n",
    "def save_show(fig, filename):\n",
    "    path = f\"{EDA_DIR}/{filename}\"\n",
    "    fig.savefig(path, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(\"saved:\", path)\n",
    "\n",
    "# ==============================================================\n",
    "# 7-A  distribution stats already printed in console\n",
    "# ==============================================================\n",
    "# no figure to save here\n",
    "\n",
    "# ==============================================================\n",
    "# 7-B  Return distribution histogram & KDE\n",
    "# ==============================================================\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "sns.histplot(df_scaled['return'], bins=80, stat='density', alpha=0.6, ax=ax)\n",
    "sns.kdeplot(df_scaled['return'], ax=ax, linewidth=2)\n",
    "ax.set_title(\"Return distribution & KDE\")\n",
    "save_show(fig, \"return_distribution.png\")\n",
    "\n",
    "# QQ-plot\n",
    "fig = qqplot(df_scaled['return'], line='s')\n",
    "plt.title(\"QQ-plot: return vs normal\")\n",
    "save_show(fig, \"return_qqplot.png\")\n",
    "\n",
    "# ==============================================================\n",
    "# 7-C  Time-series plot (returns, vol, sentiment, BOE rate)\n",
    "# ==============================================================\n",
    "fig, axes = plt.subplots(4,1, figsize=(12,10), sharex=True)\n",
    "df_scaled['return'].plot(ax=axes[0]); axes[0].set_title(\"Daily return\")\n",
    "df_scaled['rv_30d'].plot(ax=axes[1]); axes[1].set_title(\"30-day realised vol\")\n",
    "df_scaled['sent_bank_7d'].plot(ax=axes[2]); axes[2].set_title(\"Bank sentiment 7-day MA\")\n",
    "df_scaled['boe_rate_z'].plot(ax=axes[3]); axes[3].set_title(\"BOE rate (z-score)\")\n",
    "plt.tight_layout()\n",
    "save_show(fig, \"timeseries_overview.png\")\n",
    "\n",
    "# ==============================================================\n",
    "# 7-D  Correlation heatmap & rolling correlation\n",
    "# ==============================================================\n",
    "corr = df_scaled[['return','abs_ret','rv_30d','sent_bank_7d','sent_macro_7d',\n",
    "                  'boe_rate_z','yield_10y_z']].corr()\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", ax=ax)\n",
    "ax.set_title(\"Correlation matrix\")\n",
    "save_show(fig, \"corr_heatmap.png\")\n",
    "corr.to_csv(f\"{EDA_DIR}/correlation_matrix.csv\")\n",
    "\n",
    "# rolling correlation\n",
    "roll = df_scaled[['sent_bank_7d','rv_30d']].rolling(180).corr().dropna()\n",
    "series = roll.loc[pd.IndexSlice[:,'sent_bank_7d'],'rv_30d'].droplevel(1)\n",
    "fig, ax = plt.subplots(figsize=(9,3))\n",
    "series.plot(ax=ax); ax.axhline(0, ls='--', c='k')\n",
    "ax.set_title(\"180-day rolling corr: sentiment vs volatility\")\n",
    "save_show(fig, \"rolling_corr_sent_vs_vol.png\")\n",
    "\n",
    "# ==============================================================\n",
    "# 7-E  Sentiment vs next-day abs return\n",
    "# ==============================================================\n",
    "df_tmp = pd.DataFrame({\n",
    "    'sent_bank_7d': df_scaled['sent_bank_7d'],\n",
    "    'abs_ret_t+1' : df_scaled['abs_ret'].shift(-1)\n",
    "}).dropna()\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "sns.regplot(x='sent_bank_7d', y='abs_ret_t+1',\n",
    "            data=df_tmp, scatter_kws={'s':10,'alpha':0.3}, ax=ax)\n",
    "ax.set_title(\"Bank sentiment vs next-day abs return\")\n",
    "save_show(fig, \"sentiment_vs_nextday_vol.png\")\n",
    "df_tmp.corr().to_csv(f\"{EDA_DIR}/sentiment_future_vol_corr.csv\")\n",
    "\n",
    "# ==============================================================\n",
    "# 7-F  ACF / PACF & QQ stats\n",
    "# ==============================================================\n",
    "fig, axes = plt.subplots(2,1, figsize=(10,6))\n",
    "plot_acf(df_scaled['return'], lags=40, ax=axes[0])\n",
    "plot_pacf(df_scaled['return'], lags=40, ax=axes[1])\n",
    "axes[0].set_title(\"ACF â€“ returns\"); axes[1].set_title(\"PACF â€“ returns\")\n",
    "save_show(fig, \"acf_pacf_returns.png\")\n",
    "\n",
    "# ADF test results txt\n",
    "adf_stat, adf_p, *_ = adfuller(df_scaled['return'])\n",
    "with open(f\"{EDA_DIR}/adf_test.txt\", 'w') as f:\n",
    "    f.write(f\"ADF stat = {adf_stat:.4f}\\np-value = {adf_p:.6f}\\n\")\n",
    "print(\"saved: adf_test.txt\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ All EDA figures & files saved in:\", EDA_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6R9gtS51Avh"
   },
   "source": [
    "# 8 Benchmark VAR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nOoIi-RKOcDK"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet arch statsmodels scipy tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6jd5TEZ1iU-"
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from arch import arch_model\n",
    "from scipy import stats\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NPXNlA51OvA"
   },
   "outputs": [],
   "source": [
    "#8-A æ•°æ®é›†åˆ’åˆ†\n",
    "ALPHA       = 0.05           # 95% VaR\n",
    "ROLL_WIN    = 250            # HS / FHS rolling window\n",
    "SPLIT_DATE  = '2022-01-01'   # è®­ç»ƒ â€“ æµ‹è¯•åˆ†å‰²\n",
    "\n",
    "train_ret = df_scaled.loc[:SPLIT_DATE, 'return'] * 100   # *100 for arch (ç™¾åˆ†æ•°)\n",
    "test_ret  = df_scaled.loc[SPLIT_DATE:, 'return'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 124,
     "status": "ok",
     "timestamp": 1751152737027,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "zUDufR841Uth",
    "outputId": "3656ff27-c8f7-40eb-9de5-d86d3980ace3"
   },
   "outputs": [],
   "source": [
    "#8-B GARCH(1,1) + Student-t\n",
    "#8-B-1 æ‹Ÿåˆ\n",
    "garch = arch_model(train_ret, mean='Zero', vol='GARCH',\n",
    "                   p=1, q=1, dist='StudentsT').fit(disp=\"off\")\n",
    "print(garch.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "ad97edeb99994f1f8e28afdc1809bd28",
      "c34ad22e7b654c34a6508854776dbe9e",
      "2afb2cf4e0b04e6c8b0c3f868b449478",
      "82e44f4dcfe745119a1f6b475ceeea19",
      "3bfdca7db2fe4eb8bcdcbd12a21910e8",
      "9ff8b9244ae443598ffa9fe8c730b6c0",
      "1eec0995a5584eab9b1f475705059573",
      "2462c633711f4092952b84493ca94410",
      "cc76120f519f4da9a219795fca1bc5b0",
      "8acc29c1af3d42ed9855a08104c1b70e",
      "79479db130d345fca11b2929085cc19c"
     ]
    },
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1751152830107,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "2ZbV77Ee1aGm",
    "outputId": "0660037a-9987-43cc-f3b4-e62850d86566"
   },
   "outputs": [],
   "source": [
    "#8-B-2 æ»šåŠ¨é¢„æµ‹ VaR\n",
    "def garch_rolling_var(result, test_series, alpha=ALPHA):\n",
    "    \"\"\"\n",
    "    result : fitted ARCHModelResult (GARCH(1,1)-t)\n",
    "    test_series : pd.Series of daily returns *100\n",
    "    returns     : pd.Series of VaR forecasts (positive number)\n",
    "    \"\"\"\n",
    "    params = result.params\n",
    "    omega  = params['omega']\n",
    "    alpha1 = params['alpha[1]']\n",
    "    beta1  = params['beta[1]']\n",
    "    nu     = params['nu']\n",
    "\n",
    "    # last in-sample conditional variance & residual\n",
    "    sigma_prev = result.conditional_volatility.iloc[-1]\n",
    "    eps_prev   = result.std_resid.iloc[-1] * sigma_prev\n",
    "\n",
    "    var_list = []\n",
    "\n",
    "    for ret in tqdm(test_series, desc=\"GARCH rolling\"):\n",
    "        # one-step-ahead variance forecast\n",
    "        h_t = omega + alpha1 * eps_prev**2 + beta1 * sigma_prev**2\n",
    "        sigma_t = np.sqrt(h_t)\n",
    "\n",
    "        q = stats.t.ppf(alpha, df=nu)          # left-tail quantile (<0)\n",
    "        var_list.append(-(sigma_t * q) / 100)  # back to raw scale (+)\n",
    "\n",
    "        # update for next iteration\n",
    "        eps_prev   = ret                        # because mean=0 in model\n",
    "        sigma_prev = sigma_t\n",
    "\n",
    "    return pd.Series(var_list, index=test_series.index, name='VaR_garch')\n",
    "\n",
    "\n",
    "VaR_garch = garch_rolling_var(garch, test_ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "b503d53f58f341aabe9dcb17413cb245",
      "293206fbd7df41119b4caf0e6cfd015a",
      "09e151a49edd41e1b7059f5be1b6673d",
      "9e1360f87e714f3ba0595a3e04e5cd35",
      "a2962b87195c4013a9e479606cd60f72",
      "68f18baa8dd04d1cb539f416ec5edb97",
      "5e1838b1888a46128eb93120bab8c8fe",
      "909399c6df2341eab44fbbe4bca47897",
      "ddeee22411c64956addc603865047c51",
      "cd5033580ea54276898aaaa86ae7ffe5",
      "7efc8bbcca884136ae33dbda100f769a"
     ]
    },
    "executionInfo": {
     "elapsed": 1197,
     "status": "ok",
     "timestamp": 1751152893020,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "gVU9e0fd1d8a",
    "outputId": "6ed42a85-9e44-4dbc-b40f-7f3b242dc312"
   },
   "outputs": [],
   "source": [
    "#8-C æ»šåŠ¨åŽ†å²æ¨¡æ‹Ÿ (HS)\n",
    "def hs_var(train_series, test_series, win=ROLL_WIN, alpha=ALPHA):\n",
    "    var_series = []\n",
    "    history = train_series.copy()\n",
    "    for date, ret in tqdm(test_series.items(), desc=\"HS rolling\"):\n",
    "        var = -np.quantile(history/100, alpha)   # history still *100, rescale back\n",
    "        var_series.append(var)\n",
    "        history = pd.concat([history, pd.Series([ret], index=[date])]).iloc[-win:]\n",
    "    return pd.Series(var_series, index=test_series.index, name='VaR_hs')\n",
    "\n",
    "VaR_hs = hs_var(train_ret, test_ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "ba519c4da12b428ea1553e1e240bda42",
      "25508fe05dad4b94bc19d0fe4ed59a4d",
      "cd80bda8764b404ca8ed2a39998769c4",
      "989e98d0f98d495cb10b74a27347a538",
      "a4fcd861783e4fc7adb7f84e3cf6dd75",
      "5ecbbac966334d6eade91b971a0be576",
      "e82541e3cf4d4a11aa6ed8fcac2a31b1",
      "6622d3ab9af44113a7532423251681c4",
      "6caa096c6eb040d59130667d4b070b9d",
      "3b9a7e7e29514963b2902ce697497358",
      "0127675e8e0a4fd6bd34ece269cc1ac8"
     ]
    },
    "executionInfo": {
     "elapsed": 727,
     "status": "ok",
     "timestamp": 1751152976021,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "hcZSNFim2Jaz",
    "outputId": "6de0180c-aa69-4d3b-9fc3-9fc7dbfbd18d"
   },
   "outputs": [],
   "source": [
    "#8-D Filtered Historical Simulation (FHS)\n",
    "# 1) get standardized residuals from fitted GARCH\n",
    "std_resid_train = garch.std_resid * np.sqrt((garch.params['nu']-2)/garch.params['nu'])\n",
    "\n",
    "def fhs_var(result, test_series, alpha=ALPHA, win=ROLL_WIN):\n",
    "    \"\"\"\n",
    "    Filtered Historical Simulation (FHS) VaR\n",
    "    result      : fitted ARCHModelResult (è®­ç»ƒæœŸ GARCH(1,1)-t)\n",
    "    test_series : pd.Series of returns *100\n",
    "    returns     : pd.Series VaR (æ­£å€¼)\n",
    "    \"\"\"\n",
    "    p = result.params\n",
    "    omega, a1, b1, nu = p['omega'], p['alpha[1]'], p['beta[1]'], p['nu']\n",
    "\n",
    "    # è®­ç»ƒæœŸæœ€åŽçš„ Ïƒ_T å’Œ Îµ_T\n",
    "    sigma_prev = result.conditional_volatility.iloc[-1]\n",
    "    eps_prev   = result.std_resid.iloc[-1] * sigma_prev\n",
    "\n",
    "    # åŽ†å²æ ‡å‡†åŒ–æ®‹å·®ï¼ˆt è°ƒæ•´ï¼‰\n",
    "    std_resid = result.std_resid * np.sqrt((nu-2)/nu)\n",
    "    hist_std  = pd.Series(std_resid, index=result.conditional_volatility.index).copy()\n",
    "\n",
    "    var_list = []\n",
    "\n",
    "    for date, ret in tqdm(test_series.items(), desc=\"FHS rolling\"):\n",
    "        # 1-step ahead variance\n",
    "        h_t = omega + a1 * eps_prev**2 + b1 * sigma_prev**2\n",
    "        sigma_t = np.sqrt(h_t)\n",
    "\n",
    "        # VaR = -Ïƒ_t * q_Î±(Îµ_std)\n",
    "        q = np.quantile(hist_std, alpha)\n",
    "        var_list.append(-(sigma_t * q) / 100)\n",
    "\n",
    "        # æ›´æ–°æ®‹å·®ä¸Ž Ïƒ_tï¼Œç»´æŠ¤æ»šåŠ¨çª—å£\n",
    "        eps_prev   = ret\n",
    "        sigma_prev = sigma_t\n",
    "        new_std    = eps_prev / sigma_prev\n",
    "        hist_std   = pd.concat([hist_std, pd.Series([new_std], index=[date])]).iloc[-win:]\n",
    "\n",
    "    return pd.Series(var_list, index=test_series.index, name='VaR_fhs')\n",
    "\n",
    "\n",
    "VaR_fhs = fhs_var(garch, test_ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 755,
     "status": "ok",
     "timestamp": 1751153054218,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "eEJ3W95f2Qa5",
    "outputId": "146717d6-01da-4582-96dc-64569b5a986e"
   },
   "outputs": [],
   "source": [
    "#8-E å›žæµ‹ä¸Žè¯„ä¼°\n",
    "def kupiec_test(returns, var, alpha=ALPHA):\n",
    "    breaches = (returns < -var*100)  # returns still *100\n",
    "    n, x = len(breaches), breaches.sum()\n",
    "    p_hat = x/n\n",
    "    LR_uc = -2 * ( np.log((1-alpha)**(n-x) * alpha**x) -\n",
    "                   np.log((1-p_hat)**(n-x) * p_hat**x) )\n",
    "    p_value = 1 - stats.chi2.cdf(LR_uc, df=1)\n",
    "    return x, p_value\n",
    "\n",
    "def christoffersen_test(returns, var, alpha=ALPHA):\n",
    "    breaches = (returns < -var*100).astype(int)\n",
    "    N00=N01=N10=N11=0\n",
    "    for i in range(1,len(breaches)):\n",
    "        if breaches[i-1]==0 and breaches[i]==0: N00+=1\n",
    "        if breaches[i-1]==0 and breaches[i]==1: N01+=1\n",
    "        if breaches[i-1]==1 and breaches[i]==0: N10+=1\n",
    "        if breaches[i-1]==1 and breaches[i]==1: N11+=1\n",
    "    pi0 = N01/(N00+N01) if (N00+N01)>0 else 0\n",
    "    pi1 = N11/(N10+N11) if (N10+N11)>0 else 0\n",
    "    pi  = (N01+N11)/(N00+N01+N10+N11)\n",
    "    LR_cc = -2*np.log( ( (1-pi)**(N00+N10) * pi**(N01+N11) ) /\n",
    "                       ( (1-pi0)**N00 * pi0**N01 * (1-pi1)**N10 * pi1**N11 ) )\n",
    "    p_value = 1 - stats.chi2.cdf(LR_cc, df=2)\n",
    "    return p_value\n",
    "\n",
    "def quantile_loss(returns, var, alpha=ALPHA):\n",
    "    y = returns/100\n",
    "    q = -var\n",
    "    e = y - q\n",
    "    return np.mean(np.maximum(alpha*e, (alpha-1)*e))\n",
    "\n",
    "results = {}\n",
    "for label, series in [('GARCH', VaR_garch), ('HS', VaR_hs), ('FHS', VaR_fhs)]:\n",
    "    breaches, p_kup = kupiec_test(test_ret, series, ALPHA)\n",
    "    p_ch  = christoffersen_test(test_ret, series, ALPHA)\n",
    "    ql    = quantile_loss(test_ret, series, ALPHA)\n",
    "    results[label] = [breaches, p_kup, p_ch, ql]\n",
    "\n",
    "res_df = pd.DataFrame(results, index=['#Breaches','Kupiec_p','Christoffersen_p','QLoss'])\n",
    "print(res_df.T)\n",
    "res_df.T.to_csv(f\"/content/drive/MyDrive/ai-var/models/VAR/var_backtest_stats.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "executionInfo": {
     "elapsed": 998,
     "status": "ok",
     "timestamp": 1751153330789,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "cXujD8Zr2mVB",
    "outputId": "e7844656-a2d1-4d11-a46e-657a95b00c54"
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "\n",
    "# actual returns (ç°è‰²ï¼Œç¼©æ”¾å›žåŽŸå§‹ 0â€“1 åŒºé—´)\n",
    "(test_ret/100).plot(ax=ax, color='grey', alpha=0.45, label='Return')\n",
    "\n",
    "# VaR curves (æ­£å€¼è¡¨ç¤ºæ½œåœ¨æŸå¤±)\n",
    "(-VaR_garch).plot(ax=ax, color='red',   label='GARCH VaR95')\n",
    "(-VaR_fhs).plot(  ax=ax, color='blue',  label='FHS VaR95', alpha=0.7)\n",
    "(-VaR_hs ).plot(  ax=ax, color='green', label='HS VaR95',  alpha=0.7)\n",
    "\n",
    "ax.axhline(0, color='k', linewidth=0.6)\n",
    "ax.set_title(\"VaR vs Returns (95% level)\")\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_ylabel(\"Loss level (+)  /  Return (-)\")\n",
    "\n",
    "# Save to Drive\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "path = f\"/content/drive/MyDrive/ai-var/models/VAR/var_vs_returns.png\"\n",
    "plt.savefig(path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… figure saved to:\", path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HyjlCXV02zKQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jv9O7Kou43a3"
   },
   "source": [
    "# 9 LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E__kfaiW45YH"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet torch torchvision torchaudio tqdm scikit-learn joblib\n",
    "\n",
    "import torch, torch.nn as nn, numpy as np, pandas as pd, joblib, os\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEQ_LEN    = 60          # åºåˆ—é•¿åº¦ (60 å¤©)\n",
    "BATCH      = 256         # æ‰¹å¤§å°ï¼Œå¦‚æ˜¾å­˜ä¸è¶³æ”¹å°\n",
    "EPOCHS     = 40\n",
    "ALPHA      = 0.05        # 95% VaR\n",
    "SPLIT_DATE = '2022-01-01'\n",
    "DATA_DIR   = \"/content/drive/MyDrive/ai-var/models/processed\"\n",
    "MODEL_DIR  = \"/content/drive/MyDrive/ai-var/models/LSTM\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1664,
     "status": "ok",
     "timestamp": 1751154216424,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "MyAlp6mH5hb2",
    "outputId": "ff4099e5-ae1f-456b-9854-63767313a76b"
   },
   "outputs": [],
   "source": [
    "#9-1 è¯»å–æ•°æ® & æž„é€ åºåˆ—\n",
    "# 9-1-1  load scaled features\n",
    "df = pd.read_parquet(f\"{DATA_DIR}/uk_features_scaled.parquet\")\n",
    "\n",
    "FEATURES = ['return','abs_ret','rv_30d','ret_mean_5d',\n",
    "            'sent_bank_7d','sent_macro_7d',\n",
    "            'vol_bank_30d','vol_macro_30d',\n",
    "            'boe_rate_z','yield_10y_z','boe_rate_diff_z','yield_10y_diff_z']\n",
    "TARGET   = 'return'\n",
    "\n",
    "# 9-1-2  split\n",
    "train_df = df.loc[:SPLIT_DATE]\n",
    "test_df  = df.loc[SPLIT_DATE:]\n",
    "\n",
    "# 9-1-3  build sequences ----\n",
    "def build_xy(df, seq_len=SEQ_LEN):\n",
    "    X, y = [], []\n",
    "    for i in range(seq_len, len(df)):\n",
    "        X.append(df[FEATURES].iloc[i-seq_len:i].values.astype('float32'))\n",
    "        y.append(df[TARGET].iloc[i])\n",
    "    return np.stack(X), np.array(y, dtype='float32')\n",
    "\n",
    "X_train, y_train = build_xy(train_df)\n",
    "X_test,  y_test  = build_xy(test_df)\n",
    "\n",
    "print(\"Train seq:\", X_train.shape, \" Test seq:\", X_test.shape)\n",
    "\n",
    "# convert to tensors\n",
    "train_ds = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(X_train), torch.tensor(y_train).unsqueeze(1))\n",
    "test_ds  = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(X_test), torch.tensor(y_test).unsqueeze(1))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=BATCH, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajIMVD775lfa"
   },
   "outputs": [],
   "source": [
    "#9-2 å®šä¹‰ç½‘ç»œ & Pinball Loss\n",
    "class LSTM_QR(nn.Module):\n",
    "    def __init__(self, n_feat, hidden=64, layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(n_feat, hidden, layers, batch_first=True)\n",
    "        self.fc   = nn.Linear(hidden, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:,-1])\n",
    "\n",
    "def quantile_loss(pred, target, q=ALPHA):\n",
    "    e = target - pred\n",
    "    return torch.mean(torch.maximum(q*e, (q-1)*e))\n",
    "\n",
    "model = LSTM_QR(len(FEATURES)).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1405,
     "status": "ok",
     "timestamp": 1751154222685,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "DIGMXQac5zvL",
    "outputId": "74c553c8-0c23-49ae-aef2-0142204d3f51"
   },
   "outputs": [],
   "source": [
    "#9-3 è®­ç»ƒï¼ˆå« Early-Stoppingï¼‰\n",
    "BEST_PATH = f\"{MODEL_DIR}/lstm_qr_best.pt\"\n",
    "best_val  = np.inf\n",
    "patience  = 5\n",
    "no_improve = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # ---------- training ----------\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        pred = model(xb)\n",
    "        loss = quantile_loss(pred, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running += loss.item() * len(xb)\n",
    "    train_loss = running / len(train_ds)\n",
    "\n",
    "    # ---------- validation ----------\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_pred = model(torch.tensor(X_test).to(DEVICE))\n",
    "        val_loss = quantile_loss(val_pred.cpu(), torch.tensor(y_test).unsqueeze(1)).item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | train {train_loss:.4f} | val {val_loss:.4f}\")\n",
    "\n",
    "    # ---------- early stopping ----------\n",
    "    if val_loss < best_val - 1e-4:\n",
    "        best_val = val_loss\n",
    "        no_improve = 0\n",
    "        torch.save(model.state_dict(), BEST_PATH)\n",
    "        print(\"  â†³ saved best model\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "848JxJ9C54L8"
   },
   "outputs": [],
   "source": [
    "#9-4 è½½å…¥æœ€ä½³æ¨¡åž‹ & é¢„æµ‹ VaR\n",
    "best_model = LSTM_QR(len(FEATURES)).to(DEVICE)\n",
    "best_model.load_state_dict(torch.load(BEST_PATH))\n",
    "best_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_test = best_model(torch.tensor(X_test).to(DEVICE)).cpu().numpy().flatten()\n",
    "\n",
    "# VaR95 = -é¢„æµ‹å€¼ (pred ä¸ºè´Ÿæ”¶ç›Š quantile)\n",
    "VaR_lstm = pd.Series(-pred_test, index=test_df.index[SEQ_LEN:], name='VaR_lstm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "executionInfo": {
     "elapsed": 988,
     "status": "ok",
     "timestamp": 1751154231660,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "KxqZMetd6o-e",
    "outputId": "ce18ae81-e790-4c1d-aa17-aa8dedd2801b"
   },
   "outputs": [],
   "source": [
    "#9-5 å›žæµ‹ & ä¸ŽåŸºå‡†æ¯”è¾ƒ\n",
    "# ------------------ backtest util (åŒå‰) ------------------\n",
    "def kupiec(returns, var, alpha=ALPHA):\n",
    "    exc = (returns < -var).astype(int)\n",
    "    n, x = len(exc), exc.sum()\n",
    "    p_hat = x/n\n",
    "    LR_uc = -2*( np.log((1-alpha)**(n-x) * alpha**x) -\n",
    "                 np.log((1-p_hat)**(n-x) * p_hat**x) )\n",
    "    p = 1-stats.chi2.cdf(LR_uc,1)\n",
    "    return x, p\n",
    "\n",
    "def qloss(returns, var, alpha=ALPHA):\n",
    "    y = returns\n",
    "    q = -var\n",
    "    e = y - q\n",
    "    return np.mean(np.maximum(alpha*e, (alpha-1)*e))\n",
    "\n",
    "# align returns\n",
    "ret_lstm = test_df[TARGET].iloc[SEQ_LEN:] * 100  # back to %\n",
    "stats_lstm = kupiec(ret_lstm, VaR_lstm*100)\n",
    "print(\"LSTM breaches:\", stats_lstm[0], \"Kupiec p:\", stats_lstm[1])\n",
    "print(\"LSTM QLoss:\", qloss(ret_lstm, VaR_lstm*100))\n",
    "\n",
    "# ---------- compare with GARCH / FHS ----------\n",
    "comp = pd.concat([VaR_garch, VaR_fhs, VaR_lstm], axis=1).dropna()\n",
    "ret_cmp = ret_lstm.reindex(comp.index)\n",
    "\n",
    "for name, series in comp.items():\n",
    "    b, p = kupiec(ret_cmp, series*100)\n",
    "    print(f\"{name:10s}  breaches={b:3d}  Kupiec_p={p:.3f}  QLoss={qloss(ret_cmp, series*100):.5f}\")\n",
    "\n",
    "# ---------- plotting ----------\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "(ret_cmp/100).plot(ax=ax, color='grey', alpha=0.4, label='Return')\n",
    "(-comp['VaR_garch']).plot(ax=ax, color='red',   label='GARCH')\n",
    "(-comp['VaR_fhs']).plot(  ax=ax, color='blue',  label='FHS', alpha=0.7)\n",
    "(-comp['VaR_lstm']).plot( ax=ax, color='orange',label='LSTM', alpha=0.8)\n",
    "ax.axhline(0, color='k', lw=0.5); ax.set_title(\"VaR95 â€” LSTM vs Baselines\")\n",
    "ax.legend(); plt.savefig(f\"{MODEL_DIR}/var_lstm_vs_baselines.png\", dpi=300); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIDuehI-6sSU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Fqhgorf7m9b"
   },
   "source": [
    "# 10 Hybrid GARCH + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X4y0p15p7p5S"
   },
   "outputs": [],
   "source": [
    "#æ­¥éª¤ 1-a ç”Ÿæˆè®­ç»ƒæœŸåºåˆ—\n",
    "# garch æ˜¯è®­ç»ƒå¥½ çš„ ARCHModelResult (å«è®­ç»ƒæœŸ)\n",
    "sigma_train = garch.conditional_volatility          # len = train_ret\n",
    "# æ»šåŠ¨é€’æŽ¨ Ïƒ_t åˆ°æµ‹è¯•æœŸ\n",
    "sigma_roll = []\n",
    "sigma_prev = sigma_train.iloc[-1]\n",
    "eps_prev   = garch.std_resid.iloc[-1] * sigma_prev\n",
    "omega, a1, b1 = garch.params[['omega','alpha[1]','beta[1]']]\n",
    "\n",
    "for ret in test_ret:            # test_ret å·² *100\n",
    "    h = omega + a1*eps_prev**2 + b1*sigma_prev**2\n",
    "    sigma = np.sqrt(h)\n",
    "    sigma_roll.append(sigma)\n",
    "    eps_prev, sigma_prev = ret, sigma\n",
    "\n",
    "sigma_test = pd.Series(sigma_roll, index=test_ret.index)\n",
    "\n",
    "# åˆå¹¶è¿› df_scaled ï¼ˆæ³¨æ„ /100 å›žåŽŸç‚¹ï¼‰\n",
    "df_hybrid = df_scaled.copy()\n",
    "df_hybrid['garch_sigma'] = pd.concat([sigma_train/100, sigma_test/100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3332,
     "status": "ok",
     "timestamp": 1751154391232,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "aG0Cju6k7xAb",
    "outputId": "743accfa-5c90-42ea-cc74-3a3af6dfe1f3"
   },
   "outputs": [],
   "source": [
    "#æ­¥éª¤ 1-b é‡å»ºåºåˆ—ã€è®­ç»ƒ LSTM-QR\n",
    "FEATURES_H = FEATURES + ['garch_sigma']          # åœ¨åŽŸ Feature åˆ—åŽè¿½åŠ \n",
    "SEQ_LEN     = 60\n",
    "\n",
    "def build_xy_h(df):\n",
    "    X, y = [], []\n",
    "    for i in range(SEQ_LEN, len(df)):\n",
    "        X.append(df[FEATURES_H].iloc[i-SEQ_LEN:i].values.astype('float32'))\n",
    "        y.append(df[TARGET].iloc[i])\n",
    "    return np.stack(X), np.array(y, dtype='float32')\n",
    "\n",
    "Xtr, ytr = build_xy_h(df_hybrid.loc[:SPLIT_DATE])\n",
    "Xte, yte = build_xy_h(df_hybrid.loc[SPLIT_DATE:])\n",
    "\n",
    "# æ•°æ®åŠ è½½å™¨\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(\n",
    "        torch.tensor(Xtr), torch.tensor(ytr).unsqueeze(1)\n",
    "    ), batch_size=BATCH, shuffle=True)\n",
    "\n",
    "# ç½‘ç»œåŒå‰ï¼Œåªéœ€æ”¹è¾“å…¥ç»´åº¦\n",
    "modelH = LSTM_QR(len(FEATURES_H)).to(DEVICE)\n",
    "optimH = torch.optim.Adam(modelH.parameters(), lr=1e-3)\n",
    "\n",
    "# ---------- è®­ç»ƒ (å¤ç”¨æ—©åœå¾ªçŽ¯) ----------\n",
    "# æŠŠå‰é¢çš„è®­ç»ƒå¾ªçŽ¯å˜é‡åæ”¹æˆ modelH / optimH / BEST_PATH_H\n",
    "BEST_PATH_H = f\"{MODEL_DIR}/lstm_garch_feature.pt\"\n",
    "best_val = np.inf; no_imp = 0\n",
    "for ep in range(EPOCHS):\n",
    "    modelH.train(); run=0\n",
    "    for xb,yb in train_loader:\n",
    "        xb,yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        loss = quantile_loss(modelH(xb), yb)\n",
    "        optimH.zero_grad(); loss.backward(); optimH.step()\n",
    "        run += loss.item()*len(xb)\n",
    "    tr_loss = run/len(Xtr)\n",
    "    modelH.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = quantile_loss(\n",
    "            modelH(torch.tensor(Xte).to(DEVICE)).cpu(),\n",
    "            torch.tensor(yte).unsqueeze(1)).item()\n",
    "    print(f\"[H] Ep{ep+1:02d} train{tr_loss:.4f} val{val_loss:.4f}\")\n",
    "    if val_loss < best_val-1e-4:\n",
    "        best_val = val_loss; no_imp=0\n",
    "        torch.save(modelH.state_dict(), BEST_PATH_H)\n",
    "        print(\"  save best\")\n",
    "    else:\n",
    "        no_imp+=1\n",
    "        if no_imp>=patience: print(\"Early stop.\"); break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUdYJvaY72rW"
   },
   "outputs": [],
   "source": [
    "#æ­¥éª¤ 1-c æŽ¨æ–­ & å›žæµ‹\n",
    "modelH.load_state_dict(torch.load(BEST_PATH_H))\n",
    "modelH.eval()\n",
    "with torch.no_grad():\n",
    "    predH = modelH(torch.tensor(Xte).to(DEVICE)).cpu().numpy().flatten()\n",
    "VaR_hybrid_feat = pd.Series(-predH, index=df_hybrid.loc[SPLIT_DATE:].index[SEQ_LEN:],\n",
    "                            name='VaR_hybrid_feat')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fe__IO3R8DKh"
   },
   "source": [
    "# Option 2: Weighted Integration VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9AtevtZ-78RK"
   },
   "outputs": [],
   "source": [
    "#æ­¥éª¤ 2-a å‡†å¤‡åŒæ—¥æœŸç´¢å¼•\n",
    "common_idx = VaR_garch.index.intersection(VaR_lstm.index).intersection(VaR_hs.index)\n",
    "vg, vl, vh = VaR_garch.loc[common_idx], VaR_lstm.loc[common_idx], VaR_hs.loc[common_idx]\n",
    "ret_c      = (df_scaled['return']*100).loc[common_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1751154483094,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "dDBEjjHF8Gzy",
    "outputId": "59c822f3-cd3d-400a-a98c-f4976570d88c"
   },
   "outputs": [],
   "source": [
    "#æ­¥éª¤ 2-b ä¼˜åŒ–æƒé‡\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def combine_var(w, vg, vl, vh):\n",
    "    \"\"\"weights = [wg, wl, wh], sum<=1, non-neg\"\"\"\n",
    "    return w[0]*vg + w[1]*vl + w[2]*vh\n",
    "\n",
    "def objective(w):\n",
    "    var = combine_var(w, vg, vl, vh)\n",
    "    return qloss(ret_c, var*100)      # minimize QLoss\n",
    "\n",
    "# constraints: weights >=0, sum<=1\n",
    "cons = ({'type':'ineq', 'fun': lambda w: 1 - np.sum(w)},\n",
    "        {'type':'ineq', 'fun': lambda w: w})\n",
    "w0 = np.array([0.3,0.4,0.3])\n",
    "res = minimize(objective, w0, constraints=cons, method='SLSQP')\n",
    "w_opt = res.x / res.x.sum()            # normalize to sum=1\n",
    "\n",
    "print(\"Optimal weights  GARCH | LSTM | HS =\", w_opt.round(3))\n",
    "VaR_ens = combine_var(w_opt, vg, vl, vh).rename('VaR_ensemble')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1751154518698,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "v8TfVMDB8N5s",
    "outputId": "52c4bef0-83dd-4177-e80e-5e2f8d9349dc"
   },
   "outputs": [],
   "source": [
    "#æ­¥éª¤ 2-c å›žæµ‹\n",
    "b, p = kupiec(ret_c, VaR_ens*100)\n",
    "print(\"Ensemble  breaches=\",b,\"  Kupiec_p=\",p,\"  QLoss=\",qloss(ret_c, VaR_ens*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "executionInfo": {
     "elapsed": 1046,
     "status": "ok",
     "timestamp": 1751154558927,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "XjiVNWq58WnB",
    "outputId": "d96fde54-bf31-4c1d-c027-6085a6e25903"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "#  Detect which hybrid series you have  âžœ  pick first found\n",
    "# ------------------------------------------------------------------\n",
    "hybrid_candidates = ['VaR_hybrid_feat', 'VaR_ens']\n",
    "hybrid_name, VaR_hybrid = None, None\n",
    "for cand in hybrid_candidates:\n",
    "    if cand in globals():\n",
    "        hybrid_name = cand              # e.g. 'VaR_hybrid_feat'\n",
    "        VaR_hybrid  = globals()[cand]   # the actual Series\n",
    "        break\n",
    "\n",
    "if VaR_hybrid is None:\n",
    "    raise RuntimeError(\"âŒ No hybrid VaR series found. \"\n",
    "                       \"Run Feature-Fusion or Ensemble section first.\")\n",
    "\n",
    "print(\"Using hybrid series:\", hybrid_name,\n",
    "      \"| length =\", len(VaR_hybrid))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "#  Align all series to common date index\n",
    "# ------------------------------------------------------------------\n",
    "common_idx = (VaR_garch.index\n",
    "              .intersection(VaR_fhs.index)\n",
    "              .intersection(VaR_lstm.index)\n",
    "              .intersection(VaR_hybrid.index))\n",
    "\n",
    "comp_df = pd.concat({\n",
    "    'VaR_garch' : VaR_garch.loc[common_idx],\n",
    "    'VaR_fhs'   : VaR_fhs.loc[common_idx],\n",
    "    'VaR_lstm'  : VaR_lstm.loc[common_idx],\n",
    "    'VaR_hybrid': VaR_hybrid.loc[common_idx]\n",
    "}, axis=1)\n",
    "\n",
    "ret_plot = (df_scaled['return']*100).loc[common_idx]   # returns still *100\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "#  Plot returns + four VaR curves\n",
    "# ------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt, os\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "\n",
    "(ret_plot/100).plot(ax=ax, color='grey', alpha=0.4, label='Return')\n",
    "(-comp_df['VaR_garch']).plot( ax=ax, color='red',    label='GARCH')\n",
    "(-comp_df['VaR_fhs']).plot(   ax=ax, color='blue',   label='FHS',   alpha=0.7)\n",
    "(-comp_df['VaR_lstm']).plot(  ax=ax, color='orange', label='LSTM',  alpha=0.8)\n",
    "(-comp_df['VaR_hybrid']).plot(ax=ax, color='purple', label='Hybrid',alpha=0.9)\n",
    "\n",
    "ax.axhline(0, color='k', lw=0.6)\n",
    "ax.set_ylabel(\"Loss level (+) / Return (âˆ’)\")\n",
    "ax.set_title(\"VaR95 â€” Hybrid vs Baselines\")\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "#  Save figure\n",
    "# ------------------------------------------------------------------\n",
    "SAVE_DIR = \"/content/drive/MyDrive/ai-var/models/VAR\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "fig_path = f\"{SAVE_DIR}/var_hybrid_vs_baselines.png\"\n",
    "plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Figure saved to:\", fig_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TwJH8lmm8gLW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "py2d7BBo8w7R"
   },
   "source": [
    "# 11 VaR predictions and backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1751154685499,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "C32X8qnP82ZP",
    "outputId": "1791597a-b66f-4d9e-a686-7b391b4ad322"
   },
   "outputs": [],
   "source": [
    "#11-Aæ•´åˆæ‰€æœ‰ VaR åºåˆ— + å¯¹é½æ”¶ç›Š\n",
    "#  1. ç»„åˆæ‰€æœ‰éœ€è¦è¯„ä¼°çš„ VaR åˆ—\n",
    "var_dict = {\n",
    "    \"GARCH\"   : VaR_garch,          # å·²åœ¨æ­¥éª¤ 8 å¾—åˆ°\n",
    "    \"FHS\"     : VaR_fhs,            # æ­¥éª¤ 8\n",
    "    \"HS\"      : VaR_hs,             # æ­¥éª¤ 8\n",
    "    \"LSTM\"    : VaR_lstm,           # æ­¥éª¤ 9\n",
    "}\n",
    "\n",
    "# å¯é€‰ Hybrid (è‹¥å˜é‡å­˜åœ¨)\n",
    "if 'VaR_hybrid_feat' in globals():\n",
    "    var_dict[\"HybridFeat\"] = VaR_hybrid_feat\n",
    "if 'VaR_ens' in globals():\n",
    "    var_dict[\"HybridEns\"]  = VaR_ens\n",
    "\n",
    "#  2. ç»Ÿä¸€ç´¢å¼•\n",
    "common_idx = set.intersection(*[set(v.index) for v in var_dict.values()])\n",
    "common_idx = sorted(common_idx)          # list of dates\n",
    "\n",
    "var_df  = pd.concat({k: v.loc[common_idx] for k,v in var_dict.items()}, axis=1)\n",
    "ret_all = (df_scaled['return']*100).loc[common_idx]   # returns still *100\n",
    "print(\"Common index length:\", len(common_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Y0fUe9a8_UM"
   },
   "outputs": [],
   "source": [
    "#11-B æ ¸å¿ƒå›žæµ‹å‡½æ•°\n",
    "from scipy import stats\n",
    "def kupiec_p(returns, var, alpha=0.05):\n",
    "    exc   = (returns < -var).astype(int)\n",
    "    n, x  = len(exc), exc.sum()\n",
    "    p_hat = x/n\n",
    "    LR_uc = -2*( np.log((1-alpha)**(n-x) * alpha**x) -\n",
    "                 np.log((1-p_hat)**(n-x) * p_hat**x) )\n",
    "    p     = 1-stats.chi2.cdf(LR_uc,1)\n",
    "    return x, p\n",
    "\n",
    "def christoffersen_p(returns, var, alpha=0.05):\n",
    "    exc = (returns < -var).astype(int)\n",
    "    N00=N01=N10=N11=0\n",
    "    for i in range(1,len(exc)):\n",
    "        a,b = exc[i-1], exc[i]\n",
    "        if a==0 and b==0: N00+=1\n",
    "        if a==0 and b==1: N01+=1\n",
    "        if a==1 and b==0: N10+=1\n",
    "        if a==1 and b==1: N11+=1\n",
    "    pi0 = N01/(N00+N01) if N00+N01 else 0\n",
    "    pi1 = N11/(N10+N11) if N10+N11 else 0\n",
    "    pi  = (N01+N11)/(N00+N01+N10+N11)\n",
    "    LR_cc = -2*np.log( ((1-pi)**(N00+N10) * pi**(N01+N11)) /\n",
    "                       (((1-pi0)**N00) * (pi0**N01) * ((1-pi1)**N10) * (pi1**N11)) )\n",
    "    p = 1-stats.chi2.cdf(LR_cc,2)\n",
    "    return p\n",
    "\n",
    "def qloss(returns, var, alpha=0.05):\n",
    "    y = returns/100\n",
    "    q = -var\n",
    "    e = y - q\n",
    "    return np.mean(np.maximum(alpha*e, (alpha-1)*e))\n",
    "\n",
    "def mean_excess(returns, var):\n",
    "    breach = returns < -var\n",
    "    if breach.any():\n",
    "        return (-returns[breach] - var[breach]).mean()/100\n",
    "    return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 121,
     "status": "ok",
     "timestamp": 1751154746542,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "2myD-ja_9CVx",
    "outputId": "ca040d93-de27-46ff-bc11-00accbad7d67"
   },
   "outputs": [],
   "source": [
    "#11-C æ‰¹é‡è®¡ç®—å¹¶ä¿å­˜ç»“æžœè¡¨\n",
    "alpha = 0.05\n",
    "rows=[]\n",
    "for name, series in var_df.items():\n",
    "    b, p_uc = kupiec_p(ret_all, series*100, alpha)\n",
    "    p_cc    = christoffersen_p(ret_all, series*100, alpha)\n",
    "    ql      = qloss(ret_all, series*100, alpha)\n",
    "    mexcess = mean_excess(ret_all, series*100)\n",
    "    rows.append([name, b, b/len(series), p_uc, p_cc, ql, mexcess])\n",
    "\n",
    "res_table = pd.DataFrame(rows, columns=[\"Model\",\"#Breaches\",\"BreachRate\",\n",
    "                                        \"Kupiec_p\",\"Christoff_p\",\"PinballLoss\",\n",
    "                                        \"MeanExcess\"])\n",
    "\n",
    "print(res_table.sort_values(\"PinballLoss\"))\n",
    "res_table.to_csv(\"/content/drive/MyDrive/ai-var/models/result/var_backtest_summary.csv\",\n",
    "                 index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "executionInfo": {
     "elapsed": 1309,
     "status": "ok",
     "timestamp": 1751154760732,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "A8lrjYVv9ONN",
    "outputId": "a1b100b5-7d42-4042-eaa4-f821b3df3502"
   },
   "outputs": [],
   "source": [
    "#11-D å›¾å½¢ï¼šæ”¶ç›Š + å…¨éƒ¨ VaR + å¼‚å¸¸ç‚¹\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "\n",
    "# plot returns\n",
    "(ret_all/100).plot(ax=ax, color='grey', lw=0.8, alpha=0.45, label='Return')\n",
    "\n",
    "# colors for models\n",
    "colors = dict(GARCH='red', FHS='blue', HS='green', LSTM='orange',\n",
    "              HybridFeat='purple', HybridEns='brown')\n",
    "for name, series in var_df.items():\n",
    "    (-series).plot(ax=ax, label=name, color=colors.get(name,'black'), alpha=0.8)\n",
    "\n",
    "# breaches (çº¢ç‚¹)\n",
    "for name, series in var_df.items():\n",
    "    breaches = ret_all < -series*100\n",
    "    ax.scatter(series.index[breaches], (-series[breaches]),\n",
    "               color=colors.get(name,'black'), s=12, marker='x')\n",
    "\n",
    "ax.axhline(0, color='k', lw=0.5)\n",
    "ax.set_title(\"VaR95 Forecasts vs Returns with Breaches\")\n",
    "ax.set_ylabel(\"VaR / Return\")\n",
    "ax.legend(ncol=3, fontsize=9)\n",
    "\n",
    "save_path = \"/content/drive/MyDrive/ai-var/models/result/var_all_models.png\"\n",
    "fig.savefig(save_path, dpi=300, bbox_inches='tight'); plt.show()\n",
    "print(\"âœ… figure saved to:\", save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jh-mwCA69RYY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyJW5PON9nBF"
   },
   "source": [
    "# 12 Result visualization and comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "executionInfo": {
     "elapsed": 635,
     "status": "ok",
     "timestamp": 1751154882669,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "PwRXnobu9qon",
    "outputId": "22fb6d10-0e00-41ef-b743-fa77f5d2462c"
   },
   "outputs": [],
   "source": [
    "#12-Aã€€æŸ±çŠ¶å›¾ï¼šè¦†ç›–çŽ‡ä¸Žç›®æ ‡ Î±\n",
    "import pandas as pd, matplotlib.pyplot as plt, os, seaborn as sns\n",
    "\n",
    "# å¦‚æžœå…³æŽ‰äº†å†…å­˜ï¼Œé‡æ–°è½½å…¥\n",
    "summary = pd.read_csv(\"/content/drive/MyDrive/ai-var/models/VAR/var_backtest_summary.csv\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "sns.barplot(x='Model', y='BreachRate', data=summary, palette='Set2', ax=ax)\n",
    "ax.axhline(0.05, color='k', ls='--', label='Target 5%')\n",
    "ax.set_title(\"Breach Rate vs Target (95% VaR)\")\n",
    "ax.set_ylabel(\"Breach Rate\"); ax.legend()\n",
    "\n",
    "save_path = \"/content/drive/MyDrive/ai-var/models/result/breach_rate_bar.png\"\n",
    "fig.savefig(save_path, dpi=300, bbox_inches='tight'); plt.show()\n",
    "print(\"ä¿å­˜:\", save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "executionInfo": {
     "elapsed": 334,
     "status": "ok",
     "timestamp": 1751154941067,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "MTCoI53c9vUP",
    "outputId": "204dd694-08e4-4d94-c269-e366d5e77891"
   },
   "outputs": [],
   "source": [
    "#12-Bã€€Pinball Loss å¯¹æ¯”\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "sns.barplot(x='Model', y='PinballLoss', data=summary, palette='Set3', ax=ax)\n",
    "ax.set_title(\"Pinball Loss (lower = better)\")\n",
    "save_path = \"/content/drive/MyDrive/ai-var/models/result/pinball_loss_bar.png\"\n",
    "fig.savefig(save_path, dpi=300, bbox_inches='tight'); plt.show()\n",
    "print(\"ä¿å­˜:\", save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "executionInfo": {
     "elapsed": 863,
     "status": "ok",
     "timestamp": 1751154968692,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "VjtxroRP99oG",
    "outputId": "da58064b-f089-4afa-f04b-d22ff3225ed6"
   },
   "outputs": [],
   "source": [
    "#12-Cã€€é›·è¾¾å›¾ï¼šå¤šæŒ‡æ ‡ç»¼åˆå¾—åˆ†\n",
    "import numpy as np\n",
    "\n",
    "metrics = ['BreachRate','PinballLoss','MeanExcess']\n",
    "# ç»Ÿä¸€æ–¹å‘ï¼šè¶Šä½Žè¶Šå¥½ â†’ ç›´æŽ¥ä½¿ç”¨\n",
    "data = summary.set_index('Model')[metrics]\n",
    "\n",
    "# å½’ä¸€åŒ–åˆ° [0,1]\n",
    "norm = (data - data.min()) / (data.max()-data.min())\n",
    "\n",
    "labels = norm.index.tolist()\n",
    "angles = np.linspace(0, 2*np.pi, len(metrics), endpoint=False).tolist()\n",
    "angles += angles[:1]\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(111, polar=True)\n",
    "for model in labels:\n",
    "    values = norm.loc[model].tolist()\n",
    "    values += values[:1]     # é—­åˆ\n",
    "    ax.plot(angles, values, label=model)\n",
    "    ax.fill(angles, values, alpha=0.1)\n",
    "\n",
    "ax.set_xticks(angles[:-1]); ax.set_xticklabels(metrics)\n",
    "ax.set_title(\"Radar â€” lower is better (normalized)\")\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.25,1.05))\n",
    "save_path = \"/content/drive/MyDrive/ai-var/models/result/radar_metrics.png\"\n",
    "fig.savefig(save_path, dpi=300, bbox_inches='tight'); plt.show()\n",
    "print(\"ä¿å­˜:\", save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "executionInfo": {
     "elapsed": 1292,
     "status": "ok",
     "timestamp": 1751155720511,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "gNmBXWcr-EQY",
    "outputId": "0cc9c6c0-55f7-44c6-d0e0-77b885bb67e5"
   },
   "outputs": [],
   "source": [
    "#12-Dã€€å¼‚å¸¸ç‚¹æ—¶é—´çƒ­å›¾ï¼ˆè°åœ¨ä½•æ—¶è¿çº¦ï¼‰\n",
    "\n",
    "breach_df = pd.DataFrame({\n",
    "    m : (ret_all < -var_df[m]*100).astype(int)\n",
    "    for m in var_df.columns\n",
    "})\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "sns.heatmap(breach_df.T, cmap=['white','red'], cbar=False, ax=ax)\n",
    "ax.set_ylabel(\"Model\"); ax.set_xlabel(\"Date\")\n",
    "ax.set_title(\"VaR Breach Heatmap (red = exception)\")\n",
    "\n",
    "save_path = \"/content/drive/MyDrive/ai-var/models/VAR/breach_heatmap.png\"\n",
    "fig.savefig(save_path, dpi=300, bbox_inches='tight'); plt.show()\n",
    "print(\"ä¿å­˜:\", save_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwHonBjRAKtq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SLMIDV9BNGo"
   },
   "source": [
    "# 13 Explainable AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 43
    },
    "executionInfo": {
     "elapsed": 6400,
     "status": "ok",
     "timestamp": 1751155815973,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "ZD_Rks7ABQns",
    "outputId": "680bd8d2-83d8-4865-874c-c503e6a9a4e3"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet shap scikit-learn tqdm\n",
    "import shap, torch, joblib, pandas as pd, numpy as np, matplotlib.pyplot as plt, os\n",
    "shap.initjs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1751156396988,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "2pPeLS3UDdKU",
    "outputId": "f38aac25-b788-4cac-9abf-eaa84ef34b7a"
   },
   "outputs": [],
   "source": [
    "#13-A LSTM å…¨å±€ç‰¹å¾é‡è¦åº¦\n",
    "#13-A-1 å‡†å¤‡æ•°æ®\n",
    "df_raw = df_raw.loc[:, ~df_raw.columns.duplicated()].copy()\n",
    "\n",
    "fit_cols  = list(scaler.feature_names_in_)\n",
    "print(\"Scaler expects:\", fit_cols)\n",
    "\n",
    "n_before = df_raw.shape[1]\n",
    "df_raw = df_raw[fit_cols]              # åªä¿ç•™ & æ­£ç¡®æŽ’åº\n",
    "n_after  = df_raw.shape[1]\n",
    "print(f\"Columns after align: {n_after} (before {n_before})\")\n",
    "\n",
    "X_full  = scaler.transform(df_raw.values)     # .values åŒ to_numpy()\n",
    "X_torch = torch.tensor(X_full, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "background = X_torch[np.random.choice(len(X_torch), 500, replace=False)]\n",
    "print(\"ðŸ‘ transform success, shape:\", X_full.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RsPYpb1PD3Ho"
   },
   "outputs": [],
   "source": [
    "#13-A-2 åˆ›å»º DeepExplainer\n",
    "\n",
    "# ===================== 13-A-2  DeepExplainer (CPU å®‰å…¨ç‰ˆ) =====================\n",
    "import copy, shap, torch, numpy as np, pandas as pd, matplotlib.pyplot as plt, os, seaborn as sns\n",
    "shap.initjs()\n",
    "\n",
    "SEQ_LEN       = 60\n",
    "N_BACKGROUND  = 200      # èƒŒæ™¯å­æ ·æœ¬æ•°\n",
    "N_EXPLAIN     = 1500     # è§£é‡Šæ ·æœ¬æ•°\n",
    "SAVE_DIR      = \"/content/drive/MyDrive/ai-var/xai\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ---------- 1) æž„é€  3-D åºåˆ— ----------\n",
    "def build_seq(arr, seq_len=SEQ_LEN):\n",
    "    return np.stack([arr[i-seq_len:i] for i in range(seq_len, len(arr))], axis=0)\n",
    "\n",
    "X_seq   = build_seq(X_full)                      # (T-SEQ, 60, feat)\n",
    "print(\"X_seq shape:\", X_seq.shape)\n",
    "\n",
    "# ---------- 2) é€‰èƒŒæ™¯ & æ ·æœ¬ ----------\n",
    "idx_bg  = np.random.choice(len(X_seq), N_BACKGROUND, replace=False)\n",
    "idx_exp = np.arange(min(N_EXPLAIN, len(X_seq)))\n",
    "\n",
    "X_bg_np  = X_seq[idx_bg]\n",
    "X_exp_np = X_seq[idx_exp]\n",
    "\n",
    "# ---------- 3) æŠŠæ¨¡åž‹ & æ•°æ®æ¬åˆ° CPU ----------\n",
    "model_cpu      = copy.deepcopy(best_model).cpu()   # æ·±æ‹·è´é˜²æ­¢æƒé‡å†²çª\n",
    "model_cpu.train()                                  # å¿…é¡» train() è®© RNN backward å¯ç”¨\n",
    "\n",
    "background_cpu = torch.tensor(X_bg_np,  dtype=torch.float32)\n",
    "X_exp_cpu      = torch.tensor(X_exp_np, dtype=torch.float32)\n",
    "\n",
    "# ---------- 4) DeepExplainer ----------\n",
    "\n",
    "model_cpu.train()\n",
    "explainer = shap.DeepExplainer(model_cpu, background_cpu)   # æ— å‚æ•°\n",
    "shap_values = explainer.shap_values(X_exp_cpu,              # å‚æ•°æ”¾è¿™é‡Œ\n",
    "                                    check_additivity=False)\n",
    "\n",
    "# ----- åŽç»­èšåˆä¸Žå¯è§†åŒ–ä¿æŒä¸å˜ -----\n",
    "\n",
    "\n",
    "# ---------- 5) èšåˆæ—¶é—´ç»´ & ç”»æŸ±çŠ¶å›¾ ----------\n",
    "shap_global = np.abs(shap_vals).mean(axis=(0,1))        # (feat,)\n",
    "shap_df     = pd.DataFrame({'Feature': scaler.feature_names_in_,\n",
    "                            'SHAP': shap_global}).sort_values('SHAP', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "sns.barplot(x='SHAP', y='Feature', data=shap_df, ax=ax, color='steelblue')\n",
    "ax.set_title(\"Global SHAP Importance (LSTM-QR)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "fig_path = f\"{SAVE_DIR}/shap_lstm_bar.png\"\n",
    "fig.savefig(fig_path, dpi=300)\n",
    "plt.show()\n",
    "print(\"âœ… SHAP bar saved to:\", fig_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTuDDq4CItkm"
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 1ï¸âƒ£  è®¡ç®— SHAP å€¼  (ç¡®ä¿ç‰ˆæœ¬æ­£ç¡® / å‚æ•°ä½ç½®æ­£ç¡®)\n",
    "# -----------------------------------------------------------\n",
    "model_cpu.train()\n",
    "explainer = shap.DeepExplainer(model_cpu, background_cpu)   # å¦‚æžœå·²å‡çº§ shapâ‰¥0.41ï¼Œå¯åŠ  check_additivity=False\n",
    "\n",
    "# â¬‡ï¸ è‹¥ç‰ˆæœ¬<0.41ï¼Œéœ€è¦æŠŠ check_additivity æ”¾åˆ°å‡½æ•°è°ƒç”¨\n",
    "shap_values = explainer.shap_values(X_exp_cpu, check_additivity=False)\n",
    "\n",
    "# shap_values è¿”å›ž listï¼›å–ç¬¬ 0 ä¸ªè¾“å‡º\n",
    "if isinstance(shap_values, list):\n",
    "    shap_vals = shap_values[0]\n",
    "else:\n",
    "    shap_vals = shap_values       # æŸäº›ç‰ˆæœ¬ç›´æŽ¥è¿”å›ž np.array\n",
    "\n",
    "print(\"shap_vals shape:\", shap_vals.shape)  # (N_samples, seq_len, n_feat)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2ï¸âƒ£  èšåˆæ—¶é—´ç»´åº¦ (å¹³å‡ç»å¯¹å€¼)\n",
    "# -----------------------------------------------------------\n",
    "import numpy as np, pandas as pd, seaborn as sns, matplotlib.pyplot as plt, os\n",
    "\n",
    "shap_global = np.abs(shap_vals).mean(axis=(0,1))      # -> (n_feat,)\n",
    "feat_names  = list(scaler.feature_names_in_)           # ä¿è¯é¡ºåºå¯¹åº”\n",
    "shap_df     = pd.DataFrame({'Feature': feat_names,\n",
    "                            'SHAP': shap_global}).sort_values('SHAP', ascending=False)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3ï¸âƒ£  ç»˜åˆ¶æŸ±çŠ¶å›¾\n",
    "# -----------------------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "sns.barplot(x='SHAP', y='Feature', data=shap_df, ax=ax, color='steelblue')\n",
    "ax.set_title(\"Global SHAP Importance (LSTM-QR)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "SAVE_DIR = \"/content/drive/MyDrive/ai-var/xai\"; os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "fig_path = f\"{SAVE_DIR}/shap_lstm_bar.png\"\n",
    "fig.savefig(fig_path, dpi=300)\n",
    "plt.show()\n",
    "print(\"âœ… SHAP bar saved to:\", fig_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1751158127229,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "rD8DQBA4KG9c",
    "outputId": "4272ef34-b6db-49b3-caf3-6032dc63ac11"
   },
   "outputs": [],
   "source": [
    "# ---------- 1) æ£€æŸ¥å¹¶åŽ»æŽ‰å¤šä½™ç»´åº¦ ----------\n",
    "print(\"raw shap_vals shape:\", shap_vals.shape)   # (N, seq_len, feat, 1)\n",
    "if shap_vals.ndim == 4 and shap_vals.shape[-1] == 1:\n",
    "    shap_vals = shap_vals.squeeze(-1)            # -> (N, seq_len, feat)\n",
    "    print(\"squeezed shap_vals shape:\", shap_vals.shape)\n",
    "\n",
    "# ---------- 2) èšåˆæ—¶é—´ç»´åº¦ (ç»å¯¹å€¼å¹³å‡) ----------\n",
    "import numpy as np, pandas as pd, seaborn as sns, matplotlib.pyplot as plt, os\n",
    "\n",
    "shap_global = np.abs(shap_vals).mean(axis=(0,1))          # (feat,)\n",
    "feat_names  = list(scaler.feature_names_in_)               # ç¡®ä¿é¡ºåº\n",
    "assert len(shap_global) == len(feat_names), \"dimension mismatch\"\n",
    "\n",
    "shap_df = (pd.DataFrame({'Feature': feat_names,\n",
    "                         'SHAP': shap_global})\n",
    "             .sort_values('SHAP', ascending=False))\n",
    "\n",
    "# ---------- 3) ç»˜åˆ¶æŸ±çŠ¶å›¾ ----------\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "sns.barplot(x='SHAP', y='Feature', data=shap_df, ax=ax, color='steelblue')\n",
    "ax.set_title(\"Global SHAP Importance (LSTM-QR)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "SAVE_DIR = \"/content/drive/MyDrive/ai-var/xai\"; os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "fig_path = f\"{SAVE_DIR}/shap_lstm_bar.png\"\n",
    "fig.savefig(fig_path, dpi=300)\n",
    "plt.show()\n",
    "print(\"âœ… SHAP bar saved to:\", fig_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "executionInfo": {
     "elapsed": 1445,
     "status": "ok",
     "timestamp": 1751158278880,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "eI0mCuy0EAhT",
    "outputId": "6afd45f3-4c4c-46bf-e137-4e6a37627857"
   },
   "outputs": [],
   "source": [
    "#13-A-3 ç»˜åˆ¶ beeswarm\n",
    "shap_bee = shap_vals.mean(axis=1)        # shape (N_samples, n_feat)\n",
    "X_bee = X_exp_np[:, -1, :]               # (N_samples, n_feat)\n",
    "\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "shap.summary_plot(\n",
    "    shap_bee,\n",
    "    features=X_bee,\n",
    "    feature_names=list(scaler.feature_names_in_),\n",
    "    show=False\n",
    ")\n",
    "\n",
    "save_dir = \"/content/drive/MyDrive/ai-var/xai\"; os.makedirs(save_dir, exist_ok=True)\n",
    "fig.savefig(f\"{save_dir}/shap_lstm_beeswarm.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… beeswarm saved to:\", f\"{save_dir}/shap_lstm_beeswarm.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "executionInfo": {
     "elapsed": 596,
     "status": "ok",
     "timestamp": 1751158381197,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "X27mLT0xKYNt",
    "outputId": "20218143-a474-4982-accc-8583b95c266e"
   },
   "outputs": [],
   "source": [
    "#13-B å•æ—¥å±€éƒ¨è§£é‡Š (Waterfall)\n",
    "\n",
    "import shap, torch, pandas as pd, numpy as np, matplotlib.pyplot as plt, os\n",
    "\n",
    "sample_date = breach_df.index[breach_df.any(axis=1)][0]     # âœ” axis=1\n",
    "sample_date = pd.Timestamp(sample_date)                     # è½¬å›ž Timestamp\n",
    "print(\"Sample date:\", sample_date)\n",
    "\n",
    "idx_df = df_raw.index.get_loc(sample_date)                  # å…¨æ•°æ®è¡Œå·\n",
    "idx_seq = idx_df - SEQ_LEN                                  # åºåˆ—å¼ é‡è¡Œå·\n",
    "assert idx_seq >= 0, \"sample_date æ—©äºŽ SEQ_LEN å¤©ï¼Œæ— æ³•è§£é‡Š\"\n",
    "\n",
    "sample_tensor = X_seq_torch[idx_seq : idx_seq+1]            # shape (1,60,feat)\n",
    "\n",
    "sv = explainer.shap_values(sample_tensor, check_additivity=False)[0][0]  # (60, feat)\n",
    "\n",
    "sv_avg = sv.mean(axis=0)                                    # (feat,)\n",
    "base   = explainer.expected_value[0]\n",
    "\n",
    "shap_exp = shap.Explanation(values=sv_avg,\n",
    "                            base_values=base,\n",
    "                            feature_names=scaler.feature_names_in_)\n",
    "\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "shap.plots.waterfall(shap_exp, max_display=12, show=False)\n",
    "\n",
    "save_dir = \"/content/drive/MyDrive/ai-var/xai\"; os.makedirs(save_dir, exist_ok=True)\n",
    "fig_path = f\"{save_dir}/shap_lstm_{sample_date.strftime('%Y%m%d')}.png\"\n",
    "fig.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Waterfall saved to:\", fig_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "executionInfo": {
     "elapsed": 3981,
     "status": "ok",
     "timestamp": 1751158592964,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "f4yFMgGDK0ue",
    "outputId": "93c0f08b-f25b-4659-80aa-8b4d3c08da16"
   },
   "outputs": [],
   "source": [
    "#13-C Permutation Importance\n",
    "import numpy as np, pandas as pd, seaborn as sns, matplotlib.pyplot as plt, os, tqdm\n",
    "from sklearn.metrics import mean_pinball_loss\n",
    "\n",
    "# ---------- é…ç½® ----------\n",
    "SEQ_LEN    = 60\n",
    "ALPHA      = 0.05                     # 95% VaR çš„ pinball Î±\n",
    "SAVE_DIR   = \"/content/drive/MyDrive/ai-var/xai\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ---------- 1) æž„é€  3-D åºåˆ— ----------\n",
    "def build_seq(arr, seq_len=SEQ_LEN):\n",
    "    return np.stack([arr[i-seq_len:i] for i in range(seq_len, len(arr))], axis=0)\n",
    "\n",
    "X_seq_np = build_seq(X_full)                           # (N_seq, 60, feat)\n",
    "print(\"seq shape:\", X_seq_np.shape)\n",
    "\n",
    "# ---------- 2) ç›®æ ‡å‘é‡ (ç¡®ä¿ 1-D) ----------\n",
    "y_seq_np = df_raw['return'].to_numpy()[SEQ_LEN:]       # å¯èƒ½ 1-D æˆ– 2-D\n",
    "if y_seq_np.ndim > 1:\n",
    "    print(\"âš ï¸ y_seq_np is 2-D\", y_seq_np.shape, \"â†’ take first column\")\n",
    "    y_seq_np = y_seq_np[:, 0]\n",
    "print(\"y_seq_np shape:\", y_seq_np.shape)               # (N,)\n",
    "\n",
    "# ---------- 3) é¢„æµ‹å‡½æ•° (CPU) ----------\n",
    "model_cpu.eval()                                       # inference æ¨¡å¼\n",
    "def pred_fn(arr3d):\n",
    "    with torch.no_grad():\n",
    "        t = torch.tensor(arr3d, dtype=torch.float32)\n",
    "        return model_cpu(t).cpu().numpy().flatten()\n",
    "\n",
    "baseline_pred  = pred_fn(X_seq_np)\n",
    "baseline_loss  = mean_pinball_loss(y_seq_np, baseline_pred, alpha=ALPHA)\n",
    "print(\"baseline pinball loss:\", baseline_loss)\n",
    "\n",
    "# ---------- 4) æ‰‹åŠ¨ permutation importance ----------\n",
    "feat_names  = list(scaler.feature_names_in_)\n",
    "importances = []\n",
    "\n",
    "for j, name in enumerate(tqdm.tqdm(feat_names, desc=\"permuting\")):\n",
    "    X_perm = X_seq_np.copy()\n",
    "    # å¯¹æ¯ä¸ªæ—¶é—´æ­¥ç‹¬ç«‹æ‰“ä¹±ç¬¬ j ä¸ªç‰¹å¾åˆ—ï¼Œä¿æŒåºåˆ—ç»“æž„\n",
    "    for t in range(SEQ_LEN):\n",
    "        np.random.shuffle(X_perm[:, t, j])\n",
    "    perm_pred = pred_fn(X_perm)\n",
    "    loss      = mean_pinball_loss(y_seq_np, perm_pred, alpha=ALPHA)\n",
    "    importances.append(loss - baseline_loss)           # â†‘loss â‡’ è¯¥ç‰¹å¾é‡è¦\n",
    "\n",
    "imp_df = (pd.DataFrame({'Feature': feat_names,\n",
    "                        'Importance': importances})\n",
    "            .sort_values('Importance', ascending=False))\n",
    "\n",
    "# ---------- 5) ç»˜å›¾ & ä¿å­˜ ----------\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "sns.barplot(x='Importance', y='Feature', data=imp_df,\n",
    "            ax=ax, color='indianred')\n",
    "ax.set_title(\"Permutation Importance (LSTM-QR)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "fig_path = f\"{SAVE_DIR}/perm_importance_bar.png\"\n",
    "fig.savefig(fig_path, dpi=300)\n",
    "imp_df.to_csv(f\"{SAVE_DIR}/perm_importance.csv\", index=False)\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… permutation bar & csv saved in:\", SAVE_DIR)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1751158636891,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "ybGTHeUcLM0v",
    "outputId": "a08e19cd-7f6f-4628-dc3d-c66308913d33"
   },
   "outputs": [],
   "source": [
    "#13-D GARCH ç»æµŽè§£é‡Š\n",
    "params = garch.params[['omega','alpha[1]','beta[1]','nu']]\n",
    "params.to_frame(\"Estimate\").to_csv(f\"{save_dir}/garch_param_table.csv\")\n",
    "print(\"GARCH params:\\n\", params)\n",
    "\n",
    "# å¯é€‰ï¼šÏƒ_t ä¸Ž æƒ…ç»ªçš®å°”é€Š\n",
    "garch_sigma_full = pd.concat([sigma_train/100, sigma_test/100])\n",
    "corr_sent_sigma = garch_sigma_full.corr(df_scaled['sent_bank_7d'])\n",
    "print(\"Corr(Ïƒ, sentiment) =\", corr_sent_sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8jV5f8WhMD_I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0S_bwa3MN_k"
   },
   "source": [
    "# 14 Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1751158705768,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "F-GGOId_MQIL",
    "outputId": "a009832f-5c5c-4e84-ac9d-ed89db15a6a5"
   },
   "outputs": [],
   "source": [
    "#14-A ä¿å­˜ å…¨éƒ¨æ¨¡åž‹æƒé‡ä¸Žé¢„å¤„ç†å¯¹è±¡\n",
    "import torch, joblib, os, pickle, json, datetime, zipfile\n",
    "\n",
    "ROOT_DIR   = \"/content/drive/MyDrive/ai-var\"\n",
    "MODEL_DIR  = f\"{ROOT_DIR}/models\"\n",
    "SCALER_BIN = f\"{MODEL_DIR}/feature_scaler.bin\"\n",
    "\n",
    "timestamp   = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# 1) LSTM-QR\n",
    "torch.save(best_model.state_dict(), f\"{MODEL_DIR}/LSTM/lstm_qr_best_{timestamp}.pt\")\n",
    "\n",
    "# 2) Hybrid (å¦‚æžœæœ‰)\n",
    "if 'modelH' in globals():        # Feature-fusion\n",
    "    torch.save(modelH.state_dict(),\n",
    "               f\"{MODEL_DIR}/LSTM/lstm_hybrid_feat_{timestamp}.pt\")\n",
    "\n",
    "# 3) ä¿å­˜ StandardScalerï¼ˆè‹¥æœªä¿å­˜ï¼‰\n",
    "if not os.path.exists(SCALER_BIN):\n",
    "    joblib.dump(scaler, SCALER_BIN)\n",
    "\n",
    "# 4) ä¿å­˜ GARCH ç»“æžœå¯¹è±¡ (pickled)\n",
    "with open(f\"{MODEL_DIR}/garch_result_{timestamp}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(garch, f)\n",
    "\n",
    "print(\"âœ… Models & scaler saved with timestamp:\", timestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1751158712235,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "pnvHIni6MU0C",
    "outputId": "93d5c00f-1a76-4e2e-f99f-bd0396144d52"
   },
   "outputs": [],
   "source": [
    "#14-B ä¿å­˜ å…¨éƒ¨ DataFrame / VaR é¢„æµ‹ç»“æžœ\n",
    "import pandas as pd\n",
    "\n",
    "# 1) é¢„æµ‹åºåˆ—ï¼š\n",
    "var_df.to_parquet(f\"{ROOT_DIR}/processed/var_predictions_{timestamp}.parquet\")\n",
    "\n",
    "# 2) å›žæµ‹æ€»ç»“è¡¨ï¼š\n",
    "res_table.to_csv(f\"{ROOT_DIR}/processed/var_backtest_summary_{timestamp}.csv\", index=False)\n",
    "\n",
    "# 3) åŠ   XAI é‡è¦åº¦è¡¨ï¼š\n",
    "imp_df.to_csv(f\"{ROOT_DIR}/xai/perm_importance_{timestamp}.csv\", index=False)\n",
    "shap_df.to_csv(f\"{ROOT_DIR}/xai/shap_global_{timestamp}.csv\", index=False)\n",
    "\n",
    "print(\"âœ… VaR predictions & metrics saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 141,
     "status": "ok",
     "timestamp": 1751158718444,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "YtTRbTCtMWZt",
    "outputId": "f4c18c80-6da9-4b69-b7e4-2303db539855"
   },
   "outputs": [],
   "source": [
    "#14-C æ‰“åŒ… ä¸»è¦å·¥ä»¶ ä¾¿äºŽä¸‹è½½ / å½’æ¡£\n",
    "zip_path = f\"{ROOT_DIR}/ai_var_artifacts_{timestamp}.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
    "    # â€”â€” æ¨¡åž‹ â€”â€” #\n",
    "    zf.write(f\"{MODEL_DIR}/LSTM/lstm_qr_best_{timestamp}.pt\",\n",
    "             arcname=f\"models/lstm_qr_best_{timestamp}.pt\")\n",
    "    if 'modelH' in globals():\n",
    "        zf.write(f\"{MODEL_DIR}/LSTM/lstm_hybrid_feat_{timestamp}.pt\",\n",
    "                 arcname=f\"models/lstm_hybrid_feat_{timestamp}.pt\")\n",
    "    zf.write(SCALER_BIN, \"models/feature_scaler.bin\")\n",
    "    zf.write(f\"{MODEL_DIR}/garch_result_{timestamp}.pkl\",\n",
    "             arcname=f\"models/garch_result_{timestamp}.pkl\")\n",
    "\n",
    "    # â€”â€” æ•°æ® & æŒ‡æ ‡ â€”â€” #\n",
    "    zf.write(f\"{ROOT_DIR}/processed/var_predictions_{timestamp}.parquet\",\n",
    "             arcname=f\"data/var_predictions_{timestamp}.parquet\")\n",
    "    zf.write(f\"{ROOT_DIR}/processed/var_backtest_summary_{timestamp}.csv\",\n",
    "             arcname=f\"data/var_backtest_summary_{timestamp}.csv\")\n",
    "\n",
    "    # â€”â€” å›¾è¡¨ç¤ºä¾‹ â€”â€” #\n",
    "    zf.write(f\"{ROOT_DIR}/models/VAR/var_all_models.png\",\n",
    "             arcname=f\"fig/var_all_models.png\")\n",
    "    zf.write(f\"{ROOT_DIR}/xai/shap_lstm_bar.png\",\n",
    "             arcname=f\"fig/shap_lstm_bar.png\")\n",
    "\n",
    "print(\"âœ… zipped:\", zip_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1751158728672,
     "user": {
      "displayName": "Yunxiang Ji",
      "userId": "06122534331240836038"
     },
     "user_tz": -60
    },
    "id": "TpUAMlJIMX4q",
    "outputId": "df69fb40-099e-4dd7-be98-812e3744444a"
   },
   "outputs": [],
   "source": [
    "#14-D å°† å¤çŽ°ä¿¡æ¯ ä¿å­˜æˆ metadata.json\n",
    "meta = {\n",
    "    \"created\": timestamp,\n",
    "    \"models\": {\n",
    "        \"lstm_qr\": f\"models/LSTM/lstm_qr_best_{timestamp}.pt\",\n",
    "        \"hybrid_feat\": f\"models/LSTM/lstm_hybrid_feat_{timestamp}.pt\" if 'modelH' in globals() else None,\n",
    "        \"garch\": f\"models/garch_result_{timestamp}.pkl\"\n",
    "    },\n",
    "    \"scaler\": \"models/feature_scaler.bin\",\n",
    "    \"var_predictions\": f\"processed/var_predictions_{timestamp}.parquet\",\n",
    "    \"metrics\": f\"processed/var_backtest_summary_{timestamp}.csv\",\n",
    "    \"environment\": {\n",
    "        \"python\": \"3.11\",\n",
    "        \"torch\": torch.__version__,\n",
    "        \"shap\": shap.__version__\n",
    "    },\n",
    "    \"comment\": \"AI-driven VaR project â€“ full artifact snapshot\"\n",
    "}\n",
    "\n",
    "with open(f\"{ROOT_DIR}/metadata_{timestamp}.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"âœ… metadata saved:\", f\"{ROOT_DIR}/metadata_{timestamp}.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSY8fOGEMcc2"
   },
   "outputs": [],
   "source": [
    "import torch, joblib, pandas as pd, numpy as np\n",
    "\n",
    "# --- è·¯å¾„ --- (æ¢æˆæœ€æ–° time-stamp)\n",
    "model_path   = f\"{ROOT_DIR}/models/LSTM/lstm_qr_best_{timestamp}.pt\"\n",
    "scaler_path  = f\"{ROOT_DIR}/models/feature_scaler.bin\"\n",
    "lstm_loaded  = LSTM_QR(len(FEATURES)).cpu()\n",
    "lstm_loaded.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "lstm_loaded.eval()\n",
    "scaler_loaded = joblib.load(scaler_path)\n",
    "\n",
    "# --- å‡†å¤‡ä¸€ä¸ªæ–°çš„ 60Ã—feat åºåˆ— ---\n",
    "new_raw   = ...  # ä½ çš„æ–° DataFrame\n",
    "new_scaled = scaler_loaded.transform(new_raw[FEATURES])\n",
    "new_seq    = new_scaled[np.newaxis, ...]          # shape (1, 60, feat)\n",
    "with torch.no_grad():\n",
    "    pred_q = lstm_loaded(torch.tensor(new_seq, dtype=torch.float32)).item()\n",
    "VaR95_new = -pred_q\n",
    "print(\"Predicted VaR95:\", VaR95_new)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM5/5CVJ8aVMQct+Sh5PQvS",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0127675e8e0a4fd6bd34ece269cc1ac8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "09e151a49edd41e1b7059f5be1b6673d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_909399c6df2341eab44fbbe4bca47897",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ddeee22411c64956addc603865047c51",
      "value": 1
     }
    },
    "1eec0995a5584eab9b1f475705059573": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2462c633711f4092952b84493ca94410": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25508fe05dad4b94bc19d0fe4ed59a4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ecbbac966334d6eade91b971a0be576",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e82541e3cf4d4a11aa6ed8fcac2a31b1",
      "value": "FHSâ€‡rolling:â€‡"
     }
    },
    "293206fbd7df41119b4caf0e6cfd015a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68f18baa8dd04d1cb539f416ec5edb97",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5e1838b1888a46128eb93120bab8c8fe",
      "value": "HSâ€‡rolling:â€‡"
     }
    },
    "2afb2cf4e0b04e6c8b0c3f868b449478": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2462c633711f4092952b84493ca94410",
      "max": 910,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cc76120f519f4da9a219795fca1bc5b0",
      "value": 910
     }
    },
    "3b9a7e7e29514963b2902ce697497358": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bfdca7db2fe4eb8bcdcbd12a21910e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e1838b1888a46128eb93120bab8c8fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ecbbac966334d6eade91b971a0be576": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6622d3ab9af44113a7532423251681c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "68f18baa8dd04d1cb539f416ec5edb97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6caa096c6eb040d59130667d4b070b9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "79479db130d345fca11b2929085cc19c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7efc8bbcca884136ae33dbda100f769a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "82e44f4dcfe745119a1f6b475ceeea19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8acc29c1af3d42ed9855a08104c1b70e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_79479db130d345fca11b2929085cc19c",
      "value": "â€‡910/910â€‡[00:00&lt;00:00,â€‡3468.97it/s]"
     }
    },
    "8acc29c1af3d42ed9855a08104c1b70e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "909399c6df2341eab44fbbe4bca47897": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "989e98d0f98d495cb10b74a27347a538": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b9a7e7e29514963b2902ce697497358",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0127675e8e0a4fd6bd34ece269cc1ac8",
      "value": "â€‡910/?â€‡[00:00&lt;00:00,â€‡1303.33it/s]"
     }
    },
    "9e1360f87e714f3ba0595a3e04e5cd35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd5033580ea54276898aaaa86ae7ffe5",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7efc8bbcca884136ae33dbda100f769a",
      "value": "â€‡910/?â€‡[00:01&lt;00:00,â€‡623.44it/s]"
     }
    },
    "9ff8b9244ae443598ffa9fe8c730b6c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2962b87195c4013a9e479606cd60f72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4fcd861783e4fc7adb7f84e3cf6dd75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad97edeb99994f1f8e28afdc1809bd28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c34ad22e7b654c34a6508854776dbe9e",
       "IPY_MODEL_2afb2cf4e0b04e6c8b0c3f868b449478",
       "IPY_MODEL_82e44f4dcfe745119a1f6b475ceeea19"
      ],
      "layout": "IPY_MODEL_3bfdca7db2fe4eb8bcdcbd12a21910e8"
     }
    },
    "b503d53f58f341aabe9dcb17413cb245": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_293206fbd7df41119b4caf0e6cfd015a",
       "IPY_MODEL_09e151a49edd41e1b7059f5be1b6673d",
       "IPY_MODEL_9e1360f87e714f3ba0595a3e04e5cd35"
      ],
      "layout": "IPY_MODEL_a2962b87195c4013a9e479606cd60f72"
     }
    },
    "ba519c4da12b428ea1553e1e240bda42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_25508fe05dad4b94bc19d0fe4ed59a4d",
       "IPY_MODEL_cd80bda8764b404ca8ed2a39998769c4",
       "IPY_MODEL_989e98d0f98d495cb10b74a27347a538"
      ],
      "layout": "IPY_MODEL_a4fcd861783e4fc7adb7f84e3cf6dd75"
     }
    },
    "c34ad22e7b654c34a6508854776dbe9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ff8b9244ae443598ffa9fe8c730b6c0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_1eec0995a5584eab9b1f475705059573",
      "value": "GARCHâ€‡rolling:â€‡100%"
     }
    },
    "cc76120f519f4da9a219795fca1bc5b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cd5033580ea54276898aaaa86ae7ffe5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd80bda8764b404ca8ed2a39998769c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6622d3ab9af44113a7532423251681c4",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6caa096c6eb040d59130667d4b070b9d",
      "value": 1
     }
    },
    "ddeee22411c64956addc603865047c51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e82541e3cf4d4a11aa6ed8fcac2a31b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
